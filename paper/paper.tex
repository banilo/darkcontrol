\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{mdframed}
\usepackage{bbm}
\usepackage{algorithm,algorithmic}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{bbm}
\usepackage[titletoc]{appendix}
\usepackage{wrapfig}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{ulem}
\usepackage{multirow}

\def\B#1{\bm{#1}}
%\def\B#1{\mathbf{#1}}
\def\trans{\mathsf{T}}

%\renewcommand{\labelitemi}{--}

\newtheorem{theorem}{Theorem} \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}{Remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{A Computational Account of Default-Mode Function\\
by Control Theory and Reinforcement Learning}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\Prox}{Prox}
\DeclareMathOperator{\im}{im}

% macros from michael's .tex
\DeclareMathOperator{\dist}{dist} % The distance.
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\abs}{abs}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}

\def\Id{\mathbf{I}}
\def\1{\mathbf{1}}
\def\X{\mathbf{X}}
\def\U{\mathbf{U}}
\def\V{\mathbf{V}}
\def\v{\mathbf{v}}
\def\u{\mathbf{u}}
\def\z{\mathbf{z}}
\def\Y{\mathbf{Y}}
\def\A{\mathbf{A}}
\def\B{\mathbf{B}}
\def\C{\mathbf{C}}
\def\N{\mathbf{N}}
\def\R{\mathbf{R}}
\def\Q{\mathbf{Q}}
\def\P{\mathbf{P}}
\def\K{\mathbf{K}}
\def\a{\mathbf{a}}
\def\b{\mathbf{b}}
\def\s{\mathbf{s}}
\def\x{\mathbf{x}}

\newcommand{\suggestadd}[1]{{\color{blue} #1}}
\newcommand{\suggestremove}[1]{{\color{red} \sout{#1}}}

% \nipsfinalcopy % Uncomment for camera-ready version
\nipsfinaltrue
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\author{Elvis Dohmatob, (Bert Kappen), Danilo Bzdok\\
  INRIA, Parietal team, Saclay, France\\
  CEA, Neurospin, Gif-sur-Yvette, France\\
  firstname.lastname@inria.fr}

\maketitle


\begin{abstract}
The default mode network (DMN) is the neural representation of the human
baseline mental activity.
%
Many research streams agree on its likely role in evolutionarily adaptive envisioning of past and hypothetical scenarios to predict the environment.
The DMN would hence be dedicated to continuous autobiographical memory retrieval,
generation of hypothetical outcomes,
and reward contingency evaluation when letting the mind go.
It explains its highest energy consumption in the brain and its intimate coupling with conscious awareness.
%
This concept paper proposes a process model that describes
\textit{how} the DMN may actually implement continuous
environmental assessment and prediction.
DMN function is recast from the mathematical perspective of control theory and
reinforcement learning.
Neurobiological evidence on the human and animal DMN
is linked to recent progress in autonomous systems research
in the machine-learning domain.
We argue that this engineering account can parsimoneously
explain a variety of existing neuroscientific hypotheses of DMN function.
%
Formal models of the computational processes subserved by the DMN
could offer statistical control of predictive human behavior.

\end{abstract}

% official NIPS keywords
\textbf{\\keywords}: Systems Biology, mind wandering, cognitive science,
autonomous learning systems
\textbf{\\Get opinion from}: Danielle Bassett, Kai Vogeley, Mohammad Shakir,
Guillaume Dumas, Smallwood

\tableofcontents

\section{The Default-Mode Network}
%
When left unperturbed, the human brain is not at rest. Rather, the brain continues to metabolize large quantities of oxygen and glucose energy to maintain inter-neuronal information transfer in the absence of an externally structured task (Bzdok and Eickhoff, 2016a). This baseline energy demand is subject to surprisingly little modulations due to the cognitive load posed by environmental challenges. What has early been described as the "stream of consciousness" in psychology (James, 1890).
%
A few years ago, the so-called "default mode network" was discovered entirely by accident (Shulman et al., 1997). A coherent set of brain regions consistently increased in neural activity during stimulus-independent thought, which was proposed to reflect the neural correlates underlying unfocused everyday mind wandering (Raichle et al., 2001). That is, in the beginning of the 21st century, brain imaging was the first technology to allow for the discovery of a coherent brain network that subserves a set of baseline mental activity (Bzdok et al., 2012; IBzdok et al., 2015).
%
15 years ago neuroscientists have discovered an energy-demanding brain network with unique properties. The "default-mode network" (DMN) appeared exclusive in task-induced deactivation during various psychological experiments. It was later argued to be systematically anti-correlated with brain regions that subserve task performance. Today, many authors speculate that the DMN implements continuous thinking about others’ and one’s own mind states, as well as adaptive envisioning of past, hypothetical, and future events. This network might have emerged to continuously predict environmental events using mental imagery as an evolutionary advantage.
%
Since 2001, the neurobiological properties of the default mode network have been investigated and reported in more than 3,000 neuroimaging publications 
The DMN was initially believed to represent the neural correlates of unconstrained mind-wandering because of its pervasively observed activity decrease during a large array of tasks. This processing of unknown information categories in the DMN has been argued to mediate an evolutionarily conserved function for the individual. This is all the more likely because the DMN contains the two biggest hotspots of energy consumption in the entire central nervous system. DMN activity also persists to a substantial degree during the early stages of sleep (Horovitz et al., 2008) and under anesthesia (Greicius et al., 2008). However, information processing in the DMN has also repeatedly been shown to impact human behavior. Goal-directed task performance improves with decreased activity in default-mode areas (Weissman et al., 2006) and increased DMN activity is linked to more task-independent, potentially disturbing thoughts (Mason et al., 2007). 
%
the DMN is likely to control the interplay between perception–action cycles and mental imagery (Bzdok et al., 2013a; Bzdok et al., 2013b). In particular, the DMN is likely to subserve a computational mechanism by its connections to highly associative brain areas that is key for human thought across time, splace, and content domains at the interface of external world and self (IBzdok et al., 2015).
%

hierarchically deep models of the world

Its societal and economic relevance is certified by involvement in various psychiatric disorders, including schizophrenia, autism, and depression.

sensory exchanges with the world

show how a formal approach can provide generic explanations for psycho- pathology that are physiologically grounded

quantitative (and parametric) characterisations offered by computational

d Biological systems are homeostatic (or allostatic), which
means that they minimize the dispersion (entropy) of their
interoceptive and exteroceptive states.
d Entropy is the average of surprise over time, which means
that biological systems minimize the surprise associated
with their sensory states at each point in time.
d In statistics, surprise is the negative logarithm of B

perception as hypothesis testing 

Consider an organism that, in their present situation, is confronted by several choices of what to do next. Being able to accurately and richly mentally enact possible future states before making a decision would help to evaluate the desirability of different outcomes and also the planning processes needed to make them happen.

 the use of this constructive process goes far beyond simply predicting the future, to the general evaluation of fitness for purpose

scene construction processes when envisioning past, fictitious, and future events (Hassabis et al., 2007; Spreng et al., 2009).

It was observed that the more external stimuli are predictable, the more reflection processes become detached from the actual sensory environment and the more stimulus-independent, self-focused thoughts occur (Mason et al., 2007).

\begin{itemize}
  \item includes brain regions with highest baseline energy consumption in humans
  \item most active in non-disturbed mind-wandering without external influence
  \item tends to deactivate when humans engage in goal-direct tasks
  \item fluctuations in the DMN are related to lapses during and performance in
  such externally structured/focused tasks
  \item includes brain regions that come online first when waking up from
  anesthesia
  \item its network nodes are late to myelinate, an indicator of cognitive sophistication
  \item includes the most advanced processes hierarchies and has
  no direct connections with sensory regions processing external input
  \item the DMN's conceivable key role in the continuous environmental
  tracking in a generative, integrative process might explain both its highest energy consumption in the brain and its intimate coupling with conscious awareness
  \item Indeed, patients with right IPL (=DMN) damage have particular difficulties
  with multistep actions (Hartmann et al. 2005)
  and with imagined action (Sirigu et al. 1996).
  \item Lesion of the hippocampus, feeding memory and spatial information, to the
  DMN impairs future and hypothetical thinking (cf. Hassabis PNAS)

  \item
  autobiographical memory sup- plies numerous building blocks of social semantic knowl- edge (Bar 2007; Binder et al. 2009). These isolated conceptual scripts may be reassembled to enable the fore- casting of future events (Tulving 1983, 1985; Schacter et al. 2007). Similar brain mechanisms in remembering past episodes and envisioning future circumstances is supported by their engagement of identical brain areas, as evidenced by a quantitative meta-analysis (Spreng et al. 2009). Moreover, retrograde amnesic patients were repor- ted to be impaired not only in prospection but also in imagining novel experience (Hassabis et al. 2007). These findings suggest a single neural network for mentally constructing plausible semantic scenarios of detached sit- uations regardless of temporal orientation (Buckner and Carroll 2007; Hassabis and Maguire 2007). Indeed, con- struction of detached probabilistic scenes has been argued to influence ongoing decision making by estimating out- comes of behavioral choices (Boyer 2008; Suddendorf and Corballis 2007; Schilbach et al. 2008b). 
  \item
  DMN exists in monkeys [73] and rats [74]. 
  \item clinical research has corroborated default-mode network dysfunction in various psychiatric and neurological disorders
\end{itemize}

The DMN poses an unprecedented challenge to our neuroscientific understanding and methodological inventory.

Despite ramifications in health and disease, the functional role of the DMN poses an unprecedented challenge to the conventional interpretation strategies and existing methodological arsenal in the neurosciences.

Represents the physiological and pathological instantiation of a human beings' default mental repertoire, the nature of which remains largely obscure.

The DMN has now urged major attention in the neuroscientific community (Raichle et al., 2001, >6600 citations). 



\section{Control Theory and Reinforcement Learning}
\paragraph{Control Theory.}
\begin{itemize}
\item mathematically formalized dynamics systems with input, output and
feedback loops that produce error signals for adaptation
\item typically realized by (non-linear) differential equations
\item has been used to describe neural systems in the past
\item gradient update = learn/adapt system dynamics by error occurrence
\item related to notions of game theory
\item switching between states -> typically reduces to a sequential processing model
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item policy: action to take given a state
\item value: prediction of future reward
\item model: predict what the environment will do next
\item model-baseed RI learning: we try to understand the environment; it is initially unknown
\item special to RL: exploitation vs. exploration
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\end{itemize}






\section{Known Neurobiological Properties of the Default-Mode Network}
mPFC and PCC = highest metabolic consumption in the brain/highest level of basal glucose energy consumption in humans

scene con- struction processes when envisioning past, fictitious, and future events (Hassabis et al., 2007; Spreng et al., 2009; Bzdok et al., 2013).
it is not random but purposeful
draws on conceptual knowledge acquired through experience
operating on internal sources of information
Computational processes with a focus on the internal world,
when the environment is highly predictable and
external stimuli are irrelevant.
involvement of the PMC across the boundaries of classical cognitive domains

mechanistic relevance of each node -> we deconstruct

PFC
Patients with prefrontal lesions have problems in adapting to novel situations and stimuli
Stuss, D. T. \& Benson, D. F. The Frontal Lobes (Raven, New York, 1986).

vmPFC regions respond more to the value difference that will be acted on in the current trial (executed in red), and dmPFC to the currently irrelevant value difference (modeled in blue) {Nicolle, 2012 \#3750} individual. Instead activity in vmPFC reflects a choice preference that is executed and rostral dmPFC a choice preference that is modeled. Thus, dorsal regions of rostral mPFC contain value representations in the frame of reference of a modeled (as opposed to an actuated) preference irrespective of whether this applies to another’s or to one’s own likely actions and goals. Likewise, ventral mPFC contains a representation of value in the frame of reference of an executed choice, even if this executed choice reflects one’s own or another’s preferences. dmPFC that reflects the values and preferences of another individual (here temporally discounted at a rate specific to the individual), even when they are not directly relevant to the task at hand.

Simony 2016
This implies that the processing timescale of the DMN is longer than the length of single paragraphs (B40s) and that information accumulated from prior paragraphs can affect ongoing processing in this system
Our results suggest that the DMN accumulates and integrates information over minutes. Stimulus-induced correlation patterns in the DMN were largest for the intact story, greatly decreased in the paragraph scramble condition, and were almost entirely abolished in the word scramble condition.





The PMC myelinates relatively late during postnatal development in monkeys
(Goldman-Rakic, 1987), generally considered to
be a sign of phylogenetic sophistication (Flechsig, 1920).
Physiological and disturbed metabolic fluctuations in the
human PMC have been repeated related to
phenomena of changed conscious awareness,
including anesthesia (Fiset et al., 1999),
sleep (Maquet, 2000), and forms of coma (Laureys et al., 1999).      
%
The PMC has long been speculated to reflect constant computation of
the (external) environmental statistics and its (internal) representation
as an "inner minds eye" (Cavanna et al., 2006).
For instance, Bálint's syndrome is a neurological disorder of conscious
awareness that resulting from damage in the bilateral parietal cortex.
Patients are plaigued by an
inability to bind various individual features of the visual
environment into an integrated whole (i.e., simultanagnosia)
as well as inability to direct action towards 
current unattended environmental objects
(i.e., optic ataxia).
This can be viewed as a high-level impairment in the gathering
of information about alternative objects (i.e., exploration) as well as
leveraging these environmental opportunities (i.e., exploitation).
The human PMC was congruently coupled in two functional connectivity modalities
with the amygdala
(involved in significance evaluation) and
the nucleus accumbens (involved in reward evaluation).
Specifically, the human ventral posterior cingulate cortex was
the PMC region most connected to the laterobasal
(rather than centromedial or superficial) nuclei group
of the amygdala (Bzdok et al., 2013b),
which is an amygdalar subregion probably devoted to
continuously scanning environmental input
for biological significance assessment
(Adolphs, 2010; Aggleton et al., 1980; Bzdok et al., 2011; Ghods-Sharifi et al., 2009; LeDoux, 2007).
%
Indeed,
electrophysiological recordings in animals implicated the PMC in
strategic selection (Pearson et al., 2009), risk assessment (McCoy and Platt, 2005), and outcome-contingent behavioral modulation (Hayden et al., 2008),
while its retrosplenial portion was
more specifically implicated in approach-avoidance behavior (Vann et al., 2009).
Neuron spiking activity in the PMC allowed distinguishing
whether a monkey would persue an exploratory or exploitative
behavioral strategy in a complex food foraging task (Pearson2009).
Single-cell recordings in the monkey PMC
demonstrated this brain region's sensitivity to
subjective target utility (McCoy and Platt, 2005) and integration
across individual decision-making instances (Pearson et al., 2009).
This DMN node encoded the
preference or aversion to options with uncertain reward outcomes
and its spiking activity was more associated with
subjectively perceived relevance of a chosen object
than by its factual value, based on an internal currency of value
In fact, direct stimulation of PMC neurons
promoted exploratory action towards options
with unsafe reward outcomes that were previously shunned.
Graded changes in firing rates of PMC neurons
that indicated changes in upcoming trials were
distinct from neuronal firing indicating switching between choices.
%
The retrosplenial portion of the PMC can subserve evaluation of reward
contingencies and action possibilities by integrating these with
information from memory and altered perspective frames.
Regarding memory retrieval, retrosplenial lesions have been
consistently associated with anterograde and retrograde memory impairments
of various kinds of sensory information
in rabbits (Gabriel and Talk, 2001) and humans
(Rudge and Warrington, 1991; Valenstein et al., 1987).
Regarding perspective frames, this PMC subregion has been
proposed to mediates between the organism's egocentric
(i.e., focused on sensory input) and
allocentric (i.e., focused on world knowledge) viewpoints
in animals and humans
(Burgess, 2008; Epstein, 2008; Valiquette and McNamara, 2007).
%
The PCC may consequently monitor the subjective outcomes
of possible decisions and integrates that information
with memory, perspective frames, and
reward schedules into higher-level strategies. 
Perceived value that differs across individuals updates
statistical knowledge of the environment
to predict delayed reward opportunities in the future.
In doing so, the PMC continuously adapts to changes
in both the external environment and internal milieu
that modulate strategic behavioral adjustment in volatile environments
to map possiblity spaces.



The dmPFC subserves predominantly ambiguous amodal processes
across time, space, and content domains in
sensory-independent top-down pathways.
This DMN node has been described as a “mental sketchpad” (Goldman-Rakic, 1996),
potentially implicated in de-novo generation and binding
of meaning representations instructed by stored semantics and memories.
%
The dmPFC may thus enable inference, representation, and assessment
of one's own and other individuals' action and thoughts.
For instance, neural activity in human dmPFC
reflected expectations about other peoples actions and errors thereof
(Suzuki et al., 2012; van Schie et al., 2004).
dmPFC activity indeed explained the proficiency decline
of inferring other peoples thoughts in the elderly (Moran et al., 2012).
Some dmPFC neurons in macaque monkeys exhibited a preference
for processing others', rather than own, behavior
with fine-grained adjustment of contextual circumstances (Yoshida et al., 2011).
%
Such highly abstract neural computations necessarily rely on the
generation of probabilistic internal information drawing from
episodic memory retrieval, non-mnemonic scene construction processes,
and explicit knowledge of the external world.



The vmPFC subserves less ambiguous subjective-value-related evaluative processes
reward-informed and risk estimation of self-relevant environmental stimuli.
This DMN node is more closely associated with
orchestrating adapted behavior by bottom-up-driven
processing of “what matters now”.
Quantative lesion findings across  344 human individuals confirmed
a gross impairment in value-based decision making
(Glaescher et al., 2016).
The vmPFC is preferentially connected with limbic and reward-related areas.
The vmPFC has been observed to have monosynap- tical connections with the ventral striatum (VS, which anatom- ically includes the NAc) in axonal tracing studies in monkeys (Haber et al., 1995; Ferry et al., 2000).
The NAc is thought to be linked to reward mechanisms that may not only modulate motivated behavior towards basic survival needs, but also
subserve model-free reinforcement learning in humans more broadly
(O'Doherty 2015).
This is consistent with diffusion MRI (dMRI) tractography in humans and monkeys (Croxson et al., 2005) that quantified the VS to be substantially more likely connected to the vmPFC than dmPFC in both species.
Two functional connectivity modalities in humans strongly connected
the vmPFC with the nucleus accumbens (NAc), hippocampus (HC),
posterior cingulate cortex (PCC), and retrosplenial cortex (RSC).
%
The vmPFC is often proposed to be involved in (external) emotional
reactions and own (visceral) arousal.
Real or imaginged bodily states could be mapped in the vmPFC
as a bioregulatory disposition governing cognition
and decision making (Damasio, 1996; Nauta, 1971)
In studies of decision making and neuroeconomics, ventromedial prefrontal cortex (vmPFC) con- sistently reflects an individual’s subjective valuation (Behrens et al., 2008; Boorman et al., 2009; Knutson et al., 2005; Plass- mann et al., 2007)
This may be why performance within and across participants
was related to state encoding in OFC.
Such a “cognitive map” of action space was argued to encode
the current task state even when states are unobservable from sensory input,
which was shown to be critical for behavior.
The GMV of the vmPFC and VS correlated with indices of social reward attitudes and value-guided behavior (Lebreton et al., 2009).
Additionally,
independent whole-brain analyses from structural
neuroimaging studies related the gray-matter volume (GMV) of the vmPFC
(more consistently than any other
brain region) to indices of
social competence and social network complexity,
among the most complicated decision that humans and monkeys take
(Lebreton et al., 2009; Powell et al., 2010; Lewis et al., 2011; Sallet et al., 2011).
%





The HC is well known to be involved in memory and
spatial navigation in animals and humans
(von Bechterew, 1900; Scoville and Milner, 1957; O’Keefe and Dostrovsky, 1971; Maguire et al., 2000).
Its highly recursive anatomical architecture
may be specifically designed to allowing reconstruction
whole episode of experience from memory fragments.
%
While the HC in the medial temporal lobe system
is traditionally believed to allow remembering the past,
there is now increasing evidence for a role
in constructing mental models in general (Schachter/Buckner).
Indeed,
hippocampal damage [21,38–40] is
not only associated with an impairment in reexperiencing the past (i.e., amnesia),
but also thinking about one’s own future and
imagining new fictitious experiences more broadly (Hassabis/PNAS).
Mental scenes created by hippocampus-lesioned patients exposed a lack of
spatial integrity, richness in detail, and overall coherence.
%
Single-cell recordings in the animal hippocampus revealed
some constantly active neuronal ensembles whose firing coincided with
distinct locations in space while the animal navigated through its surroundings.
London taxi drivers, individuals with high performance in spatial navigation,
were shown to exhibit increased grey matter volume in the
posterior hippocampus (Maguire et al. 2006b).
But encoding and generative reconstruction in the hippocampus extends
beyond mere spatial knowledge of the environment.
Based on large-scale recordings of hippocampal neuronal populations,
complex spiking patterns can be followed across extended periods including
their modification of input-free self-generated patterns
after environmental events (buszaki2004 theta oscillations).
Specific spiking sequences, that were elicited in experimental task conditions,
have been shown to be reenacted spontaneously during sleep.
Moreover, spike sequences measured in hippocampal place cells of rats
featured reoccurred directly after experimental trials
as well as directly before upcoming experimental trials (Diba + Buzsaki 2007).
Such hippocampal ensemble burts during rest and sleep
have been proposed to be critical in communicating local information
to the neocortex for long-term storage, which includes the DMN.
These mechanisms of the hippocampus probably make important contributions to the
recollection of autobiographical memory episodes and other
reexperienced or newly generated mental scenarios (Hassabias2007).
%
The HC thus orchestrates elements of experienced environmental aspects for
consolidations based on reenactment and for integration into 
rich mental scene construction. In this view, the HC my even influence
ongoing perception in the current environment (Maguire 2016).
-> self-play in deepmind Go
-> Kai had an interesting idea: the deja-vu effect could be when you already accidentally perturbed past such that it really occures in reality later


Finally,
the right and left TPJ are known to have hemispheric differences
according to their cytoarchitectonic borders and gyrification pattern
(Caspers et al., 2008; Caspers et al., 2006).
Neuroscientific investigations on hemispheric functional specialization
have converged to the right versus left cerebral hemisphere as dominant for
attention versus language functions (Broca 1865, Wernicke 1874, Lichtheim 1885;
Gazzaniga, Bogen et al. 1965, Sperry 1982, Stephan, Marshall et al. 2003).
%
The aRTPJ is a key node network is central for
action initiation during externally structured tasks and
sensorimotor control by integrating supramodal stimulus-guided attention
(Corbetta et al., 2002).
Involvement of this DMN node was repeatedly reported in
visuo-proprioceptive conflict (Balslev et al., 2005) and
multi-modal detection of sensory changes across
visual, auditory, or tactile stimulation in a multi-modal fMRI study
(Downar et al., 2000).
In humans, direct electrical stimulation of the
RTPJ during neurosurgery was associated with altered perception
and stimulus awareness (Blanke et al., 2002).
%
Importantly, the RTPJ has been shown to be intimately related to
supramodal prediction error signaling.
Neural activity in the RTPJ has been argued to be responsible 
for stimulus-driven attentional reallocation to 
salient and surprising sources of information
as a ‘‘circuit breaker’’ that recalibrates control and maintenance systems
(Bzdok et al., 2013; Corbetta et al., 2008).
In the face of large discrepancies between actual and previously predicted
environmental events the RTPJ acts a potential switch between
externally-oriented mind sets focussed on the
sensory world and internally-oriented mind sets focussed
on self-relevant mind-wandering of possible mental scenarios.
Transient RTPJ in humans for instance disrupted the
impact of predicted intentions of other individuals (Young et al. 2010b),
a capacity believed to be subserved by the DMN.
The RTPJ might hence be an important player that shifts away
from the default active ‘‘internally directed’’ processes
to deal instead with immediate environmental objects and contexts.
-> (slow) endogeneous changes in state transitions by the policy and value matrices
For example, the alarm at the museum is not part of the task set of listening to the guide’s discussion of Hieronymous Bosch, but it is clearly a behaviourally relevant stimulus. <=> MCMC in HC / PCC


The left TPJ in turn exhibits a close topographical relationship to
Wernicke's area
involved in the comprehension or understanding of written and spoken language.
Neurological patients with damage caused to Wernicke's area
have a major impairment of language comprehension
when listening to others or reading a book.
Their speech
preserves natural rhythm and about normal syntax, yet the
voiced sentences are devoid of meaning (i.e., aphasia).
Abstracting from the typical semantic interpretations in linguistics
and neuropsychology,
the LTPJ probably mediates access to and integrating of world knowlege.
For instance, LTPJ lesions also entail problems in recognizing
others' pantomimed action towards objects
without obvious relation to processing any language content
(Varney and Damasio 1987; Rothi et al. 1991; Buxbaum et al. 2005).
%
Also inner speech hinges on knowledge retrieval of statistical structure
about the physical and inter-personal world.
Multivariate volumetric analyses showed that the internal production of
formulated thought ("language of the mind") is closely related to the left TPJ
(Geva et al., 2011).
A number of neuroimaging studies demonstrated LTPJ activity responses
to sementically aberrant words in sentences, which suggests a role
in binding a given semantic concept into an integrated whole.
Further,
episodic memory recall and imagination strongly draws on
complex world knowledge.
Isolated building blocks of world statistics probably get reassembled
in internally generated visual scenarios that
navigate present action, weigh hypothetical possibilities, and forcast the future.
%
The LTPJ may hence facilitate the automated prediction of events
by incorporating experience-derived models of the world
into ongoing action, planning, and problem solving.
world -> policy matrix driven computation
self -> value matrix driven computation


\section{Methods}

\subsection{Linear control network model for brain organization}
Consider the following linear time-invariant (LTI) dynamical system as a (toy) model for high-level brain function
\begin{equation}
  \dot{\x}(t) = \A\x(t) + \B\u(t).
  \label{eq:lti}
\end{equation}
Here, the $n$-by-$n$ matrix $\A$ denotes a model of the brain's wiring (for example a resting state connectome computed from an anatomical atlas), while the $n$-by-$k$ ``input matrix'' $\B$ describes which nodes can be controlled by us, an external \textit{controller}, via medical intervention or a careful choice of stimulus presentation, for example.
At time $t \ge 0$, let  the $n$-vector  $\x(t) := (\x_1(t),\ldots,\x_n(t))$ encodes the state of the network (one value for each node). The aim is to supply values of $\u_1(t),\ldots,\u_k(t)$ for $k \le n$ controls as a function of the time $t$,  to take the system from any prescribed initial state $\x(0) = \x^{\text{init}} \in \mathbb R^n$ to any prescribed final state $\x(\tau) = \x^{\text{fin}} \in \mathbb R^n$ in finite time $\tau < \infty$.
When such a controlling is possible, we say that the system $(\A,\B)$ is \textit{controllable}. A precise sufficient and necessary condition for such controllability is the Kalman condition: $(\A,\B)$ is controllable iff the $n \times nk$ \textit{controllability matrix}
\begin{equation}
  \C := (\B|\A\B|\ldots|\A^{n-1}\B)
\end{equation}
has full rank, i.e
\begin{equation}
  rank(\C) = n.
\end{equation}

\paragraph{How many controls do we need at best ?}
In the thermodynamic limit ($n \rightarrow \infty$), statistical physics \cite{Liu2011} gives the extremely good estimate
\begin{equation}
  n_0(\langle k\rangle, \gamma) \approx \exp\left(-\frac{1}{2}\left(\frac{\gamma-2}{\gamma - 1}\right)\langle k \rangle\right),
\end{equation}
where $\gamma \ge 1$ is the \textit{scale-free} parameter for the node-degree distribution of the network described by $\A$, and $\langle k \rangle$ is the mean degree. Letting $\gamma \rightarrow \infty$, one recovers the Erdos-Renyi value
\begin{equation}
  n_0(\langle k\rangle) = \exp\left(-\frac{1}{2}\langle k\rangle\right),
\end{equation}
which agrees perfectly with its known analytic value. One identifies two radically different regimes:
\begin{itemize}
  \item the manageable regime $\gamma > \gamma_c := 2$, in which $n_0 < 1$, and so we only need fewer controls than total number of nodes, and
\item the unmanageable regime ``$\gamma \le \gamma_c$'', in which  $n_0 = 1$, where each node must be controlled explicitly.
\end{itemize}

\paragraph{Why linear dynamics ?}
As explained in \cite{Liu2011}, the choice of linear dynamics over a more general nonlinear dynamics can be justified as follows:
\begin{itemize}
  \item  Conclusions drawn from linear dynamics can be
extended to nonlinear systems.
\item If the controllability matrix of the linearized system
has full rank at all points, then it is sufficient for most
systems to say that the actual nonlinear system is
controllable (i.e. small signal model).
\end{itemize}

\paragraph{A note on stability.}
For stability in the LTI model \eqref{eq:lti} and hence in the constrained path integral \eqref{eq:hj} below, a sufficient (and necessary ?) condition is that all eigenvalues of the $A$ have negative real-part. One way to impose this is to add self-loops with a small negative weight.
\paragraph{Meta brain.}

\subsection{Optimal control: an LQR feedback controller}
We propose to use a linear quadratic regulator (LQR) for the feedback controller. Thus, consider the time-varying \text{value function} $V: [0, \tau] \times \mathbb R^n \rightarrow \mathbb R$, defined by the following Hamilton-Jacobi cost-to-go
\begin{equation}
  \begin{split}
    &V(t, \z) := \min_{\u} \frac{1}{2}\x_{\text{fin}}^T\Q_{\text{fin}}\x_{\text{fin}} + \int_{0}^\tau\left(\frac{1}{2}\x(t)^T\Q\x(t) + \frac{1}{2}\u(t)^T\R\u(t)\right)dt,\\
    &\text{subject to } \x(t) = \z, \dot{\x}(t) = \A\x(t) + \B\u(t),
  \end{split}
  \label{eq:hj}
\end{equation}
where the matrices $\Q$ and $\R$, precised by design considerations and subject to meta-optimization, are restricted to be positive semi-definite and positive definite, respectively. A classical calculation (reminiscent of the \textit{Pontryagin minimization principle}) reveals that the optimal feedback control in \eqref{eq:hj} is given by
\begin{equation}
  \u(t) = -\K(t)\x(t),
\end{equation}
where
\begin{equation}
  \K(t) := \R^{-1}\B^T\P(t)\text{ (Kalman gain matrix)}
\end{equation}
and the time-varying positive semi-definite matrix $\P(t)$ solves following differential Riccati equation (DRE)
\begin{equation}
\begin{split}
&-\dot{\P}(t) = \A^T\P(t) + \P(t)\A - \P(t)\B\R^{-1}\B^T\P(t) + \Q\\
&\text{subject to }\P(\tau) = \Q_{\text{fin}}.
\end{split}
\end{equation}
%% \subsection{Minimal control energy controller}
\subsubsection{Related works}
The model proposed in \cite{betzel2016} can be cast in the form \eqref{eq:hj}, with the particular choice $\Q = \textbf{I} = \rho^{-1}\R$ and $\Q_{\text{fin}} = \textbf{0}$, but with a rather ad-hoc handle on stability issues and choice driver nodes...

\subsection{Demystifying the free-energy principle and active-inference}
The free-energy principle in it's present form (including notions like ``generative density'', ``recognition density'', etc.) can be traced back to works of Dayan \& Hinton \cite{dayan1995helmholtz} in which they introduced the so-called \textit{Helmholtz machine}, a hierarchical factorial directional deep belief-net.

In this section we will develop from first-principles, the bare-bones minimalistic ideas needed to build a free-energy principle for general decision-making. This ideas were first developed by Hinton et al. in the early 90s in building their Helmholtz machine. Theories like Friston's free-energy principle and active-inference will then emerge as particular instances of this general framework, with particular design choises. For example the Friston theory axiomatizes that the brain uses a (problematic, as it implicitly assumes that posterior of each hidden unit is factorial, e.g) wake-sleep algorithm to train the underlying Helmholtz machine, etc.
\begin{table}[H]
  \begin{tabular}{p{2cm}|p{11cm}}
         \hline
         \textbf{symbol}    & \textbf{description}  \\ \hline
         $\langle E\rangle_p$ & Expectation (a.k.a average) of the
         random quantity $E$ w.r.t to the probability density $p$, formally defined by $\langle E\rangle_p := \sum_{z}p(z)E(z)$.\\ \hline
         $\mathcal H(p)$ & Information-theoretic entropy of a probability density $p$, formally defined by $\mathcal H(p) := -\sum_{z}p(z)\log(p(z))$,
          with the usual convention $0 \log(0) := 0$.\\ \hline
         $D_{KL}(q||p)$ & The Kullback-Leibler divergence between the probability densities $q$ and $p$ respectively, formally defined by $D_{KL}(q||p) := \sum_{z}q(z)\log(q(z)/p(z))$.\\ \hline
             $\zeta$ & Observations. In Friston's free-energy principle this has a decomposition in to two terms: the brain's internal state $b$ and sensory inputs $s$, i.e $\zeta = (s, b).$ \\ \hline
             $\psi$ & Hidden variables. This should be understood as the unobservable states of the external environment (to which the brain is trying to adapt by learning).\\ \hline
             $p_G(.|\zeta)$ & Generative density for ...\\ \hline
         $p_R(.|\zeta)$ & Recognition density for ... Does some kind of predictive coding (?).\\ \hline
         $F_G(\zeta)$ & Helmholtz free-energy for a model $p_G$ of generating the observation $\zeta$. This measures the surprise incured upon observing $\zeta$ generated by the model $G$.\\ \hline
         $F^R_G(\zeta)$ & Variational Helmholtz free-energy from model $R$
         to $G$.  Note that $F^G_G = F_G$.\\ \hline
  \end{tabular}
  \caption{Table of notations.}
\end{table}
\subsubsection{Helmholtz free-energy and the generative model}
Our starting point will be to build an approximation $p_G$ for the true density $p$ of the observations, so that this approximate density corresponds to the partition function of thermodynamic system. So,
\begin{eqnarray}
  \begin{split}
    \text{generative surprise } &= -\log(p_G(\zeta)) = -\log(p_G(\zeta)) \times 1 = -\log(P_G(\zeta))\sum_{\psi}p_G(\psi |\zeta)\\
    &= -\sum_{\psi}p_G(\psi, \zeta)\log(p_G(\zeta))
    =-\sum_{\psi}p_G(\psi |\zeta)\log(p_G(\psi, \zeta)/p_G(\psi|\zeta))\\
    &= \sum_{\psi}p_G(\psi |\zeta)\log(p_G(\psi|\zeta))-\sum_{\psi}p_G(\psi |\zeta)\log  (p_G(\psi, \zeta))\\
    &= -\langle \log  (p_G(., \zeta)) \rangle_{p_G(. |\zeta)} - \mathcal H(p_G(. |\zeta))\\
    &= \langle E_G(., \zeta) \rangle_{p_G(. |\zeta)} - \mathcal H(p_G(. |\zeta)) := F_G(\zeta)
  \end{split}
  \label{eq:helm}
\end{eqnarray}
where $E_G(\psi, \zeta)$ is the energy at \textit{macrostate} $\psi$ of a fictive thermodynamic system defined by setting
\begin{equation}
  E_G(\psi, \zeta) := -\log(p_G(\psi, \zeta)).
  \label{eq:gibbs}
\end{equation}
%% In the above, the variable $\psi$ is a hidden variable, and can / should be interpreted as the unobservable state of the external world.
The last quantity in \eqref{eq:helm} defined formally as
\begin{equation}
  F_G(\zeta) := \langle E_G(., \zeta) \rangle_{p_G(. |\zeta)} - \mathcal H(p_G(. |\zeta))
\end{equation}
is the \textit{Helmholtz free-energy} of the external world, modelled as the physical system for which $p_G(\psi|\zeta)$ dictates the occupation probabilities of macrostates $\psi$.
Thus generative surprise and generative Helmholtz free-energy are different views on exactly the same object.

The goal of the brain is then to optimize over the generative model $G$ (to iteratively or analytically modify the generative density $p_G(.|s)$, so as to minimize their surprise. It turns out that a direct attempt to attack this optimization problem by gradient descent on the free-energy $F_G(s)$ is furtile: the parameter update steps are not ``very clean'', and require rather cumbersome and heavy computations. A workaround is then to introduce a second density $p_R(.|\zeta)$ called a \textit{recognition} density to work in tandem with the generative density $p_G(.|\zeta)$: the former dreams / fantacizes whilst the latter tries to generate sensations which match these dreams! This primal-dual idea, first proposed in Hinton et al. 1995, is at the heart of the general free-energy principle that we'll introduce shortly.

\subsubsection{Variational Helmholtz free-energy and the bottom-up recognition sub-model}
In this subsection we'll develop a very insightful upper bound for the generative surprise (i.e generate Helmholtz free-energy), called the \textit{variational} (Helmholtz) free-energy. As an avant-gout of what is to come shorty, let's just that the well-known \textit{free-energy principle} is simply a workaround whereby the minimization surprise (intractable) is replaced with the  minimization a carefully chosen upper bound thereof.

Now, invoking \eqref{eq:gibbs} and applying Bayes rule, we get the Gibbs
distribution
\begin{equation}
  p_G(\psi|\zeta) = \frac{p_G(\psi|\zeta)}{p_G(\zeta)} = \frac{\exp(-E_G(\psi, \zeta))}{Z_G(\zeta)} = \frac{\exp(-E_G(\psi, \zeta))}{Z_G(\zeta)},
\end{equation}
where $Z_G(\zeta) := \log(p_G(\zeta)) = \sum_{\psi'}\exp(-E_G(\psi',\zeta))$, the normalizing partition function for the model \ref{eq:gibbs}.
Whence $\forall \psi$, $p_G(\zeta) = Z_G(\zeta) = \exp(-E_G(\psi, \zeta)) / p_G(\psi|\zeta)$, and so we have the invariance relation
\begin{equation}
F_G(\zeta)\overset{\eqref{eq:helm}}{=} -\log(p_G(\zeta)) = -\log(Z_G(\zeta)) = E_G(\psi, \zeta) + \log(p_G(\psi|\zeta)).
  \end{equation}
Now, in the equation above, the LHS only depends on the generative model $G$ and the data point $\zeta$: it doesn't depend on the hidden variable $\psi$, etc. So, taking expectations w.r.t an arbitrary density\footnote{The conditioning in $P_R(.|\zeta)$ is because this density is selected from a world in which the sensory inputs and internal brain state vector $\zeta$ is assumed already observed.} $p_R(.|\zeta)$ yields
\begin{equation}
  \begin{split}
    F_G(\zeta) &= -\log(Z_G(\zeta)) = \langle E_G(., \zeta)\rangle_{P_R(.|\zeta)} + \sum_{\psi}p_R(\psi|\zeta)\log(p_G(\psi|\zeta))\\
    &= \langle E_G(., \zeta)\rangle_{P_R(.|\zeta)} - \mathcal H(p_R(.|\zeta)) - \sum_{\psi}p_R(\psi|\zeta)\log(p_R(\psi|\zeta)/p_G(\psi|\zeta))\\
    &= F^R_G(\zeta) - D_{KL}(P_R(.|\zeta) || P_G(.|\zeta)),
  \end{split}
  \label{eq:fe}
\end{equation}
where $F^R_G(\zeta)$ is the \textit{variational} Helmholtz free-energy from $R$ to $G$ defined by
\begin{equation}
  F^R_G(\zeta) := \langle E_G(., \zeta)\rangle_{P_R(.|\zeta)} - \mathcal H(p_R(.|\zeta))
\end{equation}
and $D_{KL}(P_R(.|\zeta) || P_G(.|\zeta))$ is the Kullback-Leibler divergence between the $p_R(.|\zeta)$ and the generative density $p_G(.|\zeta)$. Note that $F^G_G = F_G$.

\subsubsection{A general free-energy principle}
We can resume the situation as follows:
\begin{mdframed}
\begin{equation}
  \begin{split}
    \text{generative surprise } &:= -\log(p_G(\zeta)) = \underbrace{F_G(\zeta)}_{\text{generative free-energy}} \\
    &=\underbrace{F^R_G(\zeta)}_{\text{variational free-energy}} - \underbrace{D_{KL}(P_R(.|\zeta) || P_G(.|\zeta))}_{\text{complexity}} \\
    &\le F^R_G(\zeta),
    \text{ with equalitity if }p_R(.|\zeta) = p_G(.|\zeta),
    \end{split}
\end{equation}
\end{mdframed}
where we have used the fact that KL divergence is always nonnegative.
%% In fact, we have the following theorem
%% \begin{theorem}
%%   It holds that
%%   $$
%%   \text{Minimal generative surprise = minimal (Helmholtz) variational free-energy},$$
%%   i.e
%%   \begin{equation}
%%     \min_{G}F_G(\zeta) = \min_{G,R}F^R_G(\zeta)
%%     \end{equation}
%% \end{theorem}

\subsubsection{Helmholtz machines and the wake-sleep algorithm}
% \begin{mdframed}
  \textbf{Assumption:} In both generative and recognition components of the network, there is conditional independence of  neurons in the same layer, given the data. Precisely
$$
p_G(\psi^{(l)}|\zeta) = \Pi_{k=1}^{h_l}p_G(\psi_k^{(l)} | \zeta),\hspace{1cm}
p_R(\psi^{(l)}|\zeta) = \Pi_{k=1}^{h_l}p_R(\psi_k^{(l)} |\zeta)
$$
% \end{mdframed}

\subsubsection{Friston's active-inference}
This is nothing but an application of the Dayan's wake-sleep algorithm for training a Helmholtz machine model of the brain...

The following critics can be made:
\begin{itemize}
  \item 
    As noted by Dayan et al. (\textit{Variants of Helmholtz machines}), the inter-neuronal intra-layer independence which is at the center of the HM becomes severely problematic as it is agnostic to the known organization of cortical layers...
    \item A drawback of the wake-sleep algorithm is that it requires a concurrent models (generative and recognitiion), which together do not correspond to optimization of (a bound of) the marginal likelihood (because of the incorrect KL used therein, etc.).
    \end{itemize}


\subsection{Free-energy minimization via bayesian auto-encoders}
Following Kingma et al. 2014 \cite{kingma2013auto}, define the data-dependent auxiliary random function
\begin{eqnarray}
  f_{G,R}(., \zeta) :\psi \mapsto \log(p_G(\psi,\zeta)) - \log(p_R(\psi|\zeta)).
\end{eqnarray}
Then we can rewrite the
variational free-energy as
\begin{eqnarray*}
  \begin{split}
    F_G^R(\zeta) &:= \langle E_G(., \zeta) \rangle_{p_R(. |\zeta)} - \mathcal H(p_R(. |\zeta)) = \langle E_G(., \zeta) + \log(p_R(.|\zeta))\rangle_{P_R(.|\zeta)}\\
    &=\langle -\log(p_G(.,\zeta)) + \log(p_R(.|\zeta))\rangle_{P_R(.|\zeta)}\\
    &= -\langle f_{G,R}\rangle_{P_R(.|\zeta)} \approx -\frac{1}{M}\sum_{m=1}^Mf_{G,R}(\psi^{(m)}), \text{ with }\psi^{(1)},\ldots,\psi^{(M)} \sim p_R(.|\zeta), \text{ and }M \rightarrow \infty.
    \end{split}
\end{eqnarray*}

\begin{mdframed}
  \textbf{Problem:} How do we sample from the recognition density $p_R(.|\zeta)$ in such a way that the sampling process is differentiable w.r.t the weights of the recognition network $\textbf{W}^R$ ?
\end{mdframed}
\paragraph{Solution: The reparametrization trick.}


%% For fixed $p_G(.|\zeta)$, the optimal choice for $p_R(.|\zeta)$ is given analytically by
%% \begin{equation}
%%   p_R(\psi|\zeta) \propto p_G(\psi|\zeta)\exp(-\Delta E_{G \rightarrow R}(\psi, \zeta)).
%% \end{equation}

%% \subsection{A thermodynamic model for bounded rationality, aka robust
%%   optimality}
%% \begin{itemize}
%%   \item Recall that an agent is said to have \textit{bounded rationality} if they must take into account the cost of finding solutions to problems, and not just the utility of the final state.
%%   \item For example, consider an agent that must operate under a limited lifetime and/or computation cost.
%%   \item This is in contrast to agents with \textit{unbounded rationality} considered in classical game theory.
%%     \end{itemize}
%% The material presented is a revisit of \cite{braun2011path}. See also \cite{ortega2013thermodynamics}
%% \paragraph{Utility functions and conjugate pairs.}
%%   Let $(\Omega, \mathcal F, P)$ be a probablity space. A function $U: \mathcal F \rightarrow \mathbb R$ is said to be a \textit{utility function} for this space if the conditional utility $U(A|B) := U(A \cap B) - U(B)$ has the following propertites:
%%   \begin{itemize}
%%   \item additivity: $U(A_1 \cap A_2 | B) = U(A_1|B) + U(A_2|B)$, for all events $A_1, A_2, B \in \mathcal F$.    
%%   \item statistic: there exists a function $f_{U} :\mathbb R_+ \rightarrow \mathbb R$ such that $U(A|B) = f(P(A|B))$, for all events
%%     $A,B \in \mathcal F$.
%%   \item monotonicity: $f_{U}$ is strictly increasing.
%%     \end{itemize}

%% \begin{theorem}
%%   The only functions $f: \mathbb R_+ \rightarrow \mathbb R$ which is such that $U(A|B) \equiv f(P(A|B))$ any probability space $(\Omega, \mathcal F, P)$ and utility function $U$ thereupon are of the form
%%   \begin{equation}
%%     f = \alpha \log(.),
%%     \label{eq:boltzmann}
%%   \end{equation}
%%   where $\alpha > 0$.
%% \end{theorem}

%% \textbf{XXX: equation \eqref{eq:boltzmann} above looks like Boltzmann's formula (on his gravestone...)!}

%% Such $U$ and $P$ are said to form a \textit{conjugate pair} at temperature $\alpha$.


%% \paragraph{Example.}
%% Given a utility function $U$ on a probability space $(\Omega, \mathcal F, *)$, the \textit{Gibbs measure} at temperature $\alpha > 0$ and energy levels $(-U(\omega))_{\omega \in \Omega}$ is defined to be the probability measure (on thesame measurable space)
%%   \begin{equation}
%%     P(\omega) = \frac{1}{Z_{U}(\alpha)}\exp\left(\frac{1}{\alpha}U(\omega)\right), \; \forall \omega \in \Omega,
%%   \end{equation}
%%   where

%%   \begin{equation}
%%     Z_{U}(\alpha) := \sum_{\omega \in \Omega}\exp\left(\frac{1}{\alpha}U(\omega)\right)
%%   \end{equation}
%%   is a normalization constant called the \textit{partition function} of $U$.
%%   It's not hard to see that $U$ and the $P$ above form a conjugate pair.

%%   \paragraph{Free-utility functional.}
%%     Let $(U, P)$ be a conjugate pair at temperature $\alpha > 0$  on a measurable space $(\Omega, \mathcal F)$. Given another probability measure $P'$ on the same space, define it's \textit{free utility} as
%%     \begin{equation}
%%       J(P'|U, P) = \langle U \rangle_{P'} + \alpha \mathcal H(P'),
%%     \label{eq:free_u}
%%     \end{equation}
%%     where
%%     \begin{equation}
%%       \mathcal H(P') := \langle \log(P') \rangle_{P'} := -\sum_{\omega \in \Omega}P'(\omega)\log(P'(\omega))
%%     \end{equation}
%%     is the \textit{entropy} of $P'$ (measured in the Naperian base $e \approx 2.73$). It's not difficult to establish the upper bound
%%   \begin{equation}
%%     J(P'|U) \le J(P|U) = \sum_{\omega \in \Omega}U(\omega) =: U(\Omega).
%%   \end{equation}
%%   In particular, if $P$ is the Gibbs measure at temperature $\alpha$ corresponding to $U$, then the upper bound above reduces to the \textit{log-partition function}
%%   \begin{equation}
%%     J(P'|U) \le U(\Omega) = -\alpha \log(Z_{U}(\alpha)).
%%     \end{equation}

%%   \paragraph{The free-energy / utility principle (of Friston ?).}
%%   We are now in shape to introduce the notion of free-energy for model transitions, and a variational principle for optimizing it. Consider thus an initial system described by a conjugate pair $(U_{\text{ini}}, P_{\text{ini}})$ at temperature $\alpha > 0$. We want to transform this to a new model by adding constraints represented by the utility function $\Delta U$.  The resulting system has final utility $U_{\text{fin}} = U_{\text{ini}} + \Delta U$. The difference in free-utility is then
%%   \begin{equation}
%%     \Delta J_{(U_{\text{ini}}, P_{\text{ini}}) \rightarrow P_{\text{fin}}} := J_{\text{fin}} - J_{\text{ini}} = \underbrace{\langle \Delta U\rangle_{P_{\text{fin}}}}_{\textbf{accuracy}} -  \underbrace{\alpha D_{\text{KL}}(P_{\text{ini}}\|P_{\text{fin}})}_{\textbf{complexity}},
%%     \label{eq:free}
%%   \end{equation}
%%   where
%%   \begin{equation}
%%     D_{\text{KL}}(P_{\text{fin}}\|P_{\text{ini}}) := \langle \log(\P_{\text{fin}}/\P_{\text{ini}})\rangle_{\P_{\text{fin}}} := \sum_{\omega \in \Omega}\P_{\text{fin}}(\omega)\log(\P_{\text{fin}}(\omega)/\P_{\text{ini}}(\omega))
%%   \end{equation}
%%   is the Kullback-Leibler divergence, and represents the information cost (measured in energy units) of changing the initial system.
%% In the above formula, we've extensively used the fact that $(U_{\text{ini}}, P_{\text{ini}})$ is a congugate pair and so $U_{\text{ini}}(\omega) \equiv \alpha \log(P_{\text{ini}}(\omega))$ by virtue of \eqref{eq:boltzmann}.
%%   The two terms in \eqref{eq:free} (accuracy or expected gain in utility, and the complexity of the transition) can be viewed as dertiminants of bounded rational decision-making. They formalize
%% a trade-off between an expected utility $\Delta U$ (first term) and
%% the information cost of transforming Pi
%% into $P_{\text{fin}}$ (second
%% term). In this interpretation $P_{\text{ini}}$ represents an initial choice
%% probability or policy, which includes the special case of the
%% uniform distribution where the decision-maker has initially no
%% preferences between the different choices. The probability measure $P_{\text{fin}}$ is the final choice probability that we are looking for since it
%% considers the utility constraint U∗
%% that we want to optimize. We can then formulate a variational principle for bounded rationality in the probabilities $P_{\text{fin}}(\omega)$
%% \begin{equation}
%% P^*_{\text{fin}} := \underset{P_{\text{fin}}}{\text{argmax }} \Delta J_{(U_{\text{ini}}, P_{\text{ini}}) \rightarrow P_{\text{fin}}}
%%   \end{equation}

%% By differentiating the RHS of \eqref{eq:free} w.r.t $P_{\text{fin}}$ and setting to zero, we obtain the closed-form solution

%% \begin{equation}
%%   P^*_{\text{fin}}(\omega) \propto P_{\text{ini}}(\omega)\exp\left(\frac{1}{\alpha}\Delta U(\omega)\right).
%% \end{equation}

%% Two limit cases are worth considering.
%% \begin{itemize}
%% \item \textbf{Low-temperature regime $\alpha \approx 0$:} Here $\Delta J_{(U_{\text{ini}}, P_{\text{ini}}) \rightarrow P_{\text{fin}}} \approx \langle \Delta U\rangle_{P'_{\text{fin}}}$, and so it's optimal to take
%%   $$P^*_{\text{fin}}(\omega) \equiv \text{dirac}(\omega - \omega^*) = \begin{cases}1, &\mbox{if }\omega = \omega^*,\\0, &\mbox{ otherwise,}\end{cases}$$
%%   where $\omega^* := \argmax_{\omega \in \Omega}U(\omega)$. This corresponds to unbounded rational decision-making, in which the cost of transition / problem-solving is completely disregarded.
%%   \item \textbf{High-temperature regime $\alpha \rightarrow +\infty$:} In this limiting case, it's optimal to take $P^*_{\text{fin}}(\omega) \equiv P_{\text{ini}}(\omega)$, i.e the change is so costly that it's optimal to maintain the current choice probabilities.
%% \end{itemize}

%% To conclude this section, let's note that \cite{braun2011path} show how their free-energy framework (on paths) links with the well-known Hamilton-Jacobi-Bellman optimal control framework. For example, one can re-derive the Linear Quadratic Gaussian (LQG) controller, which is a generalization of the LQR in \eqref{eq:hj}...


\section{Relation to Other Cognitive Models (Danilo)}
\paragraph{Predictive Coding and Bayesian Brain Hypothesis}
abc
The Predictive Coding Framework.
construction of detached probabilistic scenes has been argued to influence ongoing decision-making by estimating outcomes of behavioral choices.

\begin{itemize}
  \item It is one of the most frequently cited hypotheses of default mode function
  \item Within this model the brain is conceptualized as a Bayesian machine
  \item Predictive coding is a framework that, in a hierarchical setting,
  is equivalent to empirical Bayesian inference
  \item External sensory input is feed-forward/bottom-up processed in the brain
  \item Their processing is compared against expected input
  \item The prediction error, i.e. the difference between sensory input
  and internal prediction, is computed at each level and passed to
  higher levels via forward connections
  \item in case of a mismatch, back-projections top-down modulate
  input processing
  \item ‘contextual integration’ for top-down modulation of sensorimotor
  processing by context-specific a-priori information.
  \item Closely related to Friston's free-energy principle: brain as inference engine
  biological systems, including brains, must minimize the long-term average of surprise;
  formulate perception as a constructive process based on internal or generative models
  \item A generative model of the world
\end{itemize}

Friston2014:

This perspective shifts away from the brain as a passive filter of sensations (or an elaborate stimulus– response link) towards a view of the brain as a statistical organ that generates hypotheses or fantasies that are tested against sensory evidence. In short, the brain is now considered a phantastic organ (from Greek phantastikos, the ability to create mental images). For many people, this perspective can be traced back to Hermann von Helmholtz and the notion of unconscious inference: that is, a pre-rational mechanism by which visual impressions are formed (eg, the seemingly automatic but erroneous belief that the sun rises and sets in the sky, as opposed to the truth that the Earth rotates around it).

Predictive coding is not a normative or descriptive scheme, it is a process theory with a biologically plausible basis—there is now much circumstantial anatomical and physiological evidence for predictive coding in the brain.12–16 In this scheme, neuronal representations in higher levels of cortical hierarchies generate predictions of representations in lower levels. These top-down predictions are compared with representations at the lower level to form a prediction
error (associated with the activity of superficial pyramidal cells). This mismatch signal is passed back up the hierarchy, to update higher representations (associated with the activity of deep pyramidal cells).

A description of biological processes as minimising (variational) free energy—a statistical measure of the surprise or improbability of sensory data, under a model of how those data were generated.

predictive coding represents a biologically plausible scheme that enables the brain to update beliefs about the world with sensory samples

 individuals spend most of their time predicting the internal (proprioceptive) and external (exteroceptive) consequences of behaviour (both their own and that of others). To fully appreciate the bilateral nature of these predictions, inference can be considered in an embodied context. In this setting, perception can be understood as resolving exteroceptive prediction errors by selecting the predictions that best explain sensations. Conversely, behaviour suppresses pro- prioceptive prediction error by changing proprioceptive sensations. This suppression relies on classic reflexes, in which equilibrium points are set by descending proprioceptive predictions (figure 1).15 This process is called active inference

providing a rich dynamical repertoire that enables the brain to respond quickly to changing inputs

the formal constraints implicit in predictive coding mandate modulatory gain control for ascending prediction errors




\paragraph{Semantic Hypothesis}
abc

\paragraph{Sentinel Hypothesis}
many investigators speculate that this central neural network reflects the brain’s relentless tracking and prediction of environmental events to adaptively optimize the organism's future action (Schacter et al., 2007).

Cognitive neuroimaging studies linked the DMN to the contemplation of others’ (Mar, 2011) and one’s thoughts (Lombardo et al., 2009) mental states, 

DMN does social cognition -> but it exists in rats and monkeys with much more poorly developped social capacities

How can a same neurobiological circuit be equally important for baseline house-keeping functions and specific task performance?

Our computational account can explain why the DMN is implicated in both a goal-directed task and an idlying rest cognitive set? -> task is policy/value updates to optmize short-term action / rest updates for mid- and long-term action


\section{Relation to Other Statistical Models (Elvis)}
\paragraph{Control Theory.}
abc

\paragraph{Reinforcement Learning.}
abc

\paragraph{Free Energy Principle.}
\begin{itemize}
  \item Ortega et al. 2013 \cite{ortega2013thermodynamics} ``Thermodynamics as a theory of decision-making with information-processing costs''
\item Friston's critic of RL \cite{fristonAIorRL} (he proposes "active inference''): "This equation (equation 18) comes from the theory of dynamic programming,
pioneered in the 1950s by Richard Bellman and colleagues [2]. To
optimise control a~pð Þ x~ under this formulation, we have to: (i)
assume the hidden states are available to the agent and (ii) solve
Equation 18 for the value-function. Solving for the value-function
is a non-trivial problem and usually involves backwards induction
or some approximation scheme like reinforcement-learning [4–6].
The free-energy formulation circumvents these problems by
prescribing the policy in terms of free-energy, which encodes
optimal control (Equation 6)"
  \end{itemize}

\section{Conclusion}
What single brain function could be most important for existence and survival of the species?
From the perspective of the human condition, it remains unclear what the nature and purpose of a domain-overarching computational mechanism implemented in the high association cortex could be to warriant the high energetic costs.

; formalize and predict; offer statistical control on the brain's default function/operations

The DMN can be viewed as a smoothing kernel extending
from the relatively recent past to the relatively close future
that constantly estimates complex non-linear gain functions.
-> This is why neuroimaging research revealed activity increases in the DMN
when 
-> This may be why perfect memory has been evolutionarily de-selected,
although it is provably feasible by the neurobiological hardware in humans




\paragraph{Acknowledgment}
% {\small The research leading to these results has received funding from the
% European Union Seventh Framework Programme (FP7/2007-2013)
% under grant agreement no. 604102 (Human Brain Project).
% Further support was received from
% the German National Academic Foundation (D.B.).
% }


\small
\bibliographystyle{splncs03}
\bibliography{refs}

\end{document}
