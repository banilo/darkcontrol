\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{bbm}
\usepackage{algorithm,algorithmic}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{bbm}
\usepackage[titletoc]{appendix}
\usepackage{wrapfig}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{ulem}
\usepackage{multirow}

\def\B#1{\bm{#1}}
%\def\B#1{\mathbf{#1}}
\def\trans{\mathsf{T}}

%\renewcommand{\labelitemi}{--}

\newtheorem{theorem}{Theorem} \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}{Remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{A Computational Account of Default-Mode Function\\by Control Theory and Reinforcement Learning}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\Prox}{Prox}
\DeclareMathOperator{\im}{im}

% macros from michael's .tex
\DeclareMathOperator{\dist}{dist} % The distance.
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\abs}{abs}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}

\def\Id{\mathbf{I}}
\def\1{\mathbf{1}}
\def\X{\mathbf{X}}
\def\U{\mathbf{U}}
\def\V{\mathbf{V}}
\def\v{\mathbf{v}}
\def\u{\mathbf{u}}
\def\z{\mathbf{z}}
\def\Y{\mathbf{Y}}
\def\A{\mathbf{A}}
\def\B{\mathbf{B}}
\def\C{\mathbf{C}}
\def\N{\mathbf{N}}
\def\R{\mathbf{R}}
\def\Q{\mathbf{Q}}
\def\P{\mathbf{P}}
\def\K{\mathbf{K}}
\def\a{\mathbf{a}}
\def\b{\mathbf{b}}
\def\s{\mathbf{s}}
\def\x{\mathbf{x}}

\newcommand{\suggestadd}[1]{{\color{blue} #1}}
\newcommand{\suggestremove}[1]{{\color{red} \sout{#1}}}

% \nipsfinalcopy % Uncomment for camera-ready version
\nipsfinaltrue
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\author{Elvis Dohmatob, (Bert Kappen), Danilo Bzdok\\
  INRIA, Parietal team, Saclay, France\\
  CEA, Neurospin, Gif-sur-Yvette, France\\
  firstname.lastname@inria.fr}

\maketitle

\begin{abstract}
ABC
%

% OUR keywords
%\textbf{\\keywords}: curse of dimensionality; semi-supervised learning;
%fMRI; systems neuroscience

% official NIPS keywords
\textbf{\\keywords}: Systems Biology, Cognitive Science, Autonomous Learning Systems

\end{abstract}

the DMN is often proposed to be dedicated to continuous auto- biographical memory retrieval, environmental assessment, emotion ap- praisal, and reward contingency evaluation when letting the mind go.

Constantly tracking and predicting changes in a variable environment is believed to then shape the internal milieu and upcoming external behav- ior adaptively




If this computational models hold some truth in them, the DMNs conceivable key role in the continuous environmental tracking in a generative, integrative process might explain both its highest energy consumption in the brain and its intimate coupling with conscious awareness.




\section{Introduction}
%
\paragraph{The Human Default Mode Network.}
\begin{itemize}
  \item includes brain regions with highest baseline energy consumption in humans
  \item most active in non-disturbed mind-wandering without external influence
  \item tends to deactivate when humans engage in goal-direct tasks
  \item fluctuations in the DMN are related to lapses during and performance in
  such externally structured/focused tasks
  \item includes brain regions that come online first when waking up from
  anesthesia
  \item its network nodes are late to myelinate, an indicator of cognitive sophistication
  \item includes the most advanced processes hierarchies and has
  no direct connections with sensory regions processing external input
  \item the DMN's conceivable key role in the continuous environmental
  tracking in a generative, integrative process might explain both its highest energy consumption in the brain and its intimate coupling with conscious awareness
  \item Indeed, patients with right IPL (=DMN) damage have particular difficulties
  with multistep actions (Hartmann et al. 2005)
  and with imagined action (Sirigu et al. 1996).
  \item Lesion of the hippocampus, feeding memory and spatial information, to the
  DMN impairs future and hypothetical thinking (cf. Hassabis PNAS)
  \item a lesion study on disturbed sleep (i.e., a state of mind
  independent of sensory stimulation but dependent on
  internally generated information) exclusively identified
  the dmPFC (Koenigs et al., 2010). Third, another VLSM study exclusively
  related the IFG and TPJ, both more strongly connected to the
  dmPFC in our study, to inner speech
  \item Bálint's syndrome: neurological disorder of conscious
  awareness resulting from damage in bilateral parietal cortex;
  "psychic paralysis of gaze", that is, the inability for internally
  motivated, targeted saccades hindering fixation of currently not
  attended features in the field of view (i.e., oculomotor apraxia).
  unable to bind various individual features of the visual
  environment into an integrated whole (i.e., simultanagnosia)
  as well as unable to navigate hand movement to a targeted
  object helped by vision (i.e., optic ataxia).
  difficulty avoiding running into objects placed ahead;
  challenged in estimating distances as well as perceiving
  spatial depth, object sizes and object orientation
\end{itemize}

\paragraph{The Predictive Coding Framework.}
\begin{itemize}
  \item It is one of the most frequently cited hypotheses of default mode function
  \item Within this model the brain is conceptualized as a Bayesian machine
  \item Predictive coding is a framework that, in a hierarchical setting,
  is equivalent to empirical Bayesian inference
  \item External sensory input is feed-forward/bottom-up processed in the brain
  \item Their processing is compared against expected input
  \item The prediction error, i.e. the difference between sensory input
  and internal prediction, is computed at each level and passed to
  higher levels via forward connections
  \item in case of a mismatch, back-projections top-down modulate
  input processing
  \item ‘contextual integration’ for top-down modulation of sensorimotor
  processing by context-specific a-priori information.
  \item Closely related to Friston's free-energy principle: brain as inference engine
  biological systems, including brains, must minimize the long-term average of surprise;
  formulate perception as a constructive process based on internal or generative models
  \item A generative model of the world
\end{itemize}



\paragraph{Control Theory.}
\begin{itemize}
\item mathematically formalized dynamics systems with input, output and
feedback loops that produce error signals for adaptation
\item typically realized by (non-linear) differential equations
\item has been used to describe neural systems in the past
\item gradient update = learn/adapt system dynamics by error occurrence
\item related to notions of game theory
\item switching between states -> typically reduces to a sequential processing model
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item policy: action to take given a state
\item value: prediction of future reward
\item model: predict what the environment will do next
\item model-baseed RI learning: we try to understand the environment; it is initially unknown
\item special to RL: exploitation vs. exploration
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\end{itemize}


\paragraph{States and Actions in Neuroscience}


state-dependent variables such as hunger, thirst and
even wealth




\paragraph{Anatomy}
 involvement of the PMC across the boundaries of classical cognitive domains
mPFC and PCC = highest metabolic consumption in the brain/highest level of basal glucose energy consumption in humans

\begin{itemize}
  \item
    vmPFC:
    \begin{itemize}
    \item
the vmPFC sub- serves predominantly non-ambiguous subjective-value-related evaluative processes driven by bottom-up pathways
memory-informed reward and risk estimation of self-relevant environmental stimuli.
\item
the vmPFC might be more closely associated with orches- trating adapted behavior by bottom-up-driven processing of “what matters now”

\item
Most importantly, independent whole-brain analyses from structural neuroimaging studies related the gray-matter volume (GMV) of the vmPFC to indices of social competence and social network complex- ity in both humans and monkeys (Lebreton et al., 2009; Powell et al., 2010; Lewis et al., 2011; Sallet et al., 2011). To our knowl- edge, none of these four correlations have been found yet for the dmPFC. Consequently, vmPFC, rather than dmPFC, anatomy appears to predict an individual’s social behavioral dispositions and social network properties,

\item
With respect to our seeds, inter-individual differences in social skills or social networks were most often related to morphological differences in the human and monkey vmPFC, in stark contrast to the dmPFC

\item
self-related behavior guided by stimulus evalua- tion and reward-learning, a voxel-based lesion-symptom map- ping (VLSM) study in 344 neurological patients demonstrated functional-anatomical specificity of the vmPFC for value-based decision-making (Gläscher et al., 2012).


\item
As to the vmPFC subnetwork, the GMV of the vmPFC and VS correlated with indices of social reward attitudes and behavior (Lebreton et al., 2009), concur- ring with vmPFC’s relation to the NAc and reward-related tasks.

\item
In both MACM and RS analy- ses, the vmPFC was more strongly connected with the nucleus accumbens (NAc), hippocampus (HC), posterior cingulate cor- tex (PCC), and retrosplenial cortex (RSC)
In both functional decoding analyses, the vmPFC was selectively associated with reward related tasks

\item
processing approach- and avoidance-relevant stimuli

\item
Glaescher: lesions -> value-based decision making  in 344 individuals
based decision-making, which included the orbitofrontal, ventro- medial, and frontopolar cortex.

\item
Indeed, the vmPFC, but not dmPFC, has been observed to have monosynap- tical connections with the ventral striatum (VS, which anatom- ically includes the NAc) in axonal tracing studies in monkeys (Haber et al., 1995; Ferry et al., 2000).
This is consistent with our results and probabilistic diffusion tensor imaging (DTI) trac- tography in humans and monkeys (Croxson et al., 2005) that quantified the VS to be substantially more likely connected to the vmPFC than dmPFC in both species.

\item
the vmPFC is preferentially connected with limbic and reward-related medial brain areas.
The NAc is thought to be linked to reward mechanisms that may not only modulate motivated behavior towards basic survival needs

\item
Such real or imagined bodily states, believed to be represented in the vmPFC, proba- bly operate as a bioregulatory disposition governing cognition and decision making (Damasio, 1996; Nauta, 1971),

\item
\end{itemize}

\item
  dmPFC:
  \begin{itemize}
    \item
dmPFC subserves predominantly ambiguous amodal metacogni- tive processes driven by top-down pathways
\item
largely sensory-independent, highly abstract (hence, less tangible) processes across time, space, and content domains.
might be top-down modulated by more dmPFC subserved higher reflective and hypothetical processing.
consistent with present functional decoding, neural activity in the dmPFC, rather than vmPFC, has been con- sistently interpreted to underlie inference, representation, and assessment of one’s own and others’ mental states in functional neuroimaging research

\item
 dmPFC (but not vmPFC) activity was related to the proficiency decline of mental state inference in elderly (Moran et al., 2012), cognitive regulation of one’s own emotional states (Ochsner et al., 2004b) and inference of another person’s emotional states (Ochsner et al., 2004a), as well as self-reported (Wagner et al., 2011) and experimentally measured (Zaki et al., 2009) proficiency in emotional state inference.

 \item
Thus, mental state inference necessarily relies on the generation of probabilistic internal information. Supported by dmPFC’s functional association with episodic memory retrieval, such prima vista non-mnemonic construction processes are likely to be subserved by the neural network underlying retrieval of past and imagination of future scenes as indicated by recent neu- roimaging experiments and meta-analyses

\item
congruently characterizes the dmPFC as a “mental sketchpad” (Goldman-Rakic, 1996) potentially impli- cated in modeling and binding plausible self- and other-related scenarios instructed by semantic concepts

\item
 sensory-independent de novo generation of mean- ing representations can only be expected from highly associative, integrative brain areas such as those of the dmPFC subnetwork

\item
the dmPFC subserves a domain-independent neural process

\item
the present results support the dmPFC’s possible involvement in domain-overarching computational mechanisms given its connections to highly associative brain areas and function- ally relation to different complex psychological processes.

\item
the dmPFC was more strongly connected with the inferior frontal gyrus (IFG), temporo-parietal junction (TPJ), and middle temporal gyrus (MTG)

\item
Concluding from previous and present connectivity findings, the dmPFC is preferentially connected with high association and heteromodal cortical areas of the lateral frontal, temporal, and parietal lobe.

\item
it is interesting to note that the vmPFC is more strongly con- nected to medial components of the default mode network (i.e., HC, PCC, RSC), whereas the dmPFC is more strongly con- nected to its lateral components (i.e., IFG, TPJ, and MTG). This dmPFC subnetwork was repeatedly related to self-focused reflec- tion (Andrews-Hanna et al., 2010), contemplation of others’ (Mar, 2011) and one’s own (Lombardo et al., 2009) mental states, mental navigation of the body in space (Maguire et al., 1997), semantic processing (Binder et al., 2009), as well as scene con- struction processes when envisioning past, fictitious, and future events (Hassabis et al., 2007; Spreng et al., 2009; Bzdok et al., 2013).


\item
a VLSM study on disturbed sleep (i.e., a state of mind independent of sensory stimulation but dependent on internally generated informa- tion) exclusively identified the dmPFC (Koenigs et al., 2010).
-> experience replay during sleep

\end{itemize}

  \item
    PCC (gradients):
    \begin{itemize}
      \item rewards (exploitation) and gathering information about alter- native options (exploration)
Such strategic decisions should incorporate not only recent reward history, but also opportunity costs and environmental statistics

\item
single-cell recordings in the monkey PCC demonstrated this brain region's sensitivity to subjective target utility (McCoy and Platt, 2005) and integration across individual outcomes in decision making (Pearson et al., 2009).
ng attraction or aversion to options with uncertain or risky rewards
. CGp activation was better predicted by the
subjective salience of a chosen target than by its actual value.

\item
experimental psychologists and behavioral ecologists
have long argued that decision making depends on the conversion
of external variables into a common internal currency of value.

\item
electrophys- iological research in animals implicated the PCC in strategic selection (Pearson et al., 2009), risk assessment (McCoy and Platt, 2005), and outcome-contingent behavioral modulation (Hayden et al., 2008), while the RSC was implicated in nav- igation and approach-avoidance behavior (Vann et al., 2009).

\item
(McCoy and Platt, 2005):
t internal representations of value lie at the very core of
decision making,
visual gambling task used in the current study affords a unique
opportunity to examine neural activity under conditions in which
subjective value, but not objective value, varied, as indicated by
subjects’ choices
-> value matrix is not the same in each agent
h the direction of impending
Our data extend those
findings, demonstrating a direct relationship between subjective preferences
for uncertain rewards, or the opportunity to harvest a
relatively large reward, and the activity of neurons thought to participate
in the allocation of attention
movement, as shown previously24,30, and the uncertainty of rewards
associated with this movement
CGp appears to carry spatial information that is scaled by
subjective preferences for particular patterns of reward outcome.
Our data indicate that CGp
neurons signal subjective biases for uncertain rewards (or, perhaps, the
potential to receive a large reward) rather than objective target value.
the spatial sensitivity of CGp neurons was enhanced under
conditions of high risk.
-> delay discounting / non-immediate reward -> reinforcement learning

\item
Pearson2009:
balance. Here we show that CGp neurons distinguish be- tween exploratory and exploitative decisions made by mon- keys in a dynamic foraging task.
 option switching [11] and integrate this information across multiple trials [11], but the present

 \item
 Together, these results invite the hypothesis that CGp is part of a network that monitors the outcomes of individual deci- sions and integrates that information into higher-level strate- gies spanning multiple choices

 \item
keys in a dynamic foraging task. Moreover, firing rates of these neurons predict in graded fashion the strategy most likely to be selected on upcoming trials. This encoding is distinct from switching between targets and is independent of the absolute magnitudes of rewards. These observations implicate CGp in the integration of individual outcomes across decision making and the modification of strategy in dynamic environments.
recorded the activity of single cingulate cortex (CGp) neurons

\item
choosing among multiple tar-
gets whose relative values changed dynamically,
neurons in posterior cingulate cortex signaled the distinction between trials on which monkeys pursued an exploratory rather than an exploitative strategy.
**learn its current value and integrate this information with their statistical knowledge of the environment to predict its relative value on upcoming trials.**


\item
Hayden2008: adapativity of subjective reward schedules tht impact the action choices
 lesion (Gabriel, 1990) studies strongly implicate CGp in working mem- ory, attention, and general arousal (Raichle and Mintun, 2006)— all processes that contribute to adaptive decision making. -> gradient defect

\item
corded activity of single neurons in monkeys per- forming a gambling task in which the reward outcome of each choice strongly influenced subsequent choices.
choices. We found that CGp neurons signaled reward outcomes in a nonlinear fashion and that outcome- contingent modulations in firing rate persisted into subsequent trials. Moreover, firing rate on any one trial predicted switching to the alternative option on the next trial. Finally, microstimulation in CGp follow- ing risky choices promoted a preference reversal for the safe option on the following trial. Collectively, these results demonstrate that CGp directly contrib- utes to the evaluative processes that support dynamic changes in decision making in volatile environments.

\item
 these observations suggest the hypothesis that CGp contributes to the integration of actions and their out- comes and thereby influences subsequent changes in behavior.
 We confirmed a causal role for CGp in outcome evaluation and behavioral adjustment by showing that microstimulation following the most desired reward out- come increased the likelihood of exploring the alternative on the next trial.

 \item
signal decision outcomes in a nonlinear fashion, maintain this information in a buffer between trials, and predict future changes in behavior. Moreover, microstimulation in CGp promotes explo- ration of the previously antipreferred option.

\item
highlight the dynamic nature of information processing in CGp, which is not restricted to any single epoch or aspect of task performance but instead continuously adapts to changes in both the external environment and internal milieu.


\item
(Patho-)Physiologically, meta- bolic fluctuations in the human PMC have been closely related to vari- ous instances of altered conscious awareness, including anesthesia (Fiset et al., 1999), sleep (Maquet, 2000), and restoration from vegeta- tive states (Laureys et al., 1999).

  \item
Electrophysiologically, gamma band re- cordings in humans (Dastjerdi et al., 2011) and single-cell recordings in monkeys (Hayden et al., 2009) revealed activity reductions in the PMC during attentionally demanding tasks compared to rest.

\item
 have long been speculated to reflect constant contemplation of (external) environment and (internal) memory

 \item
   xons in parts of the PMC myelinate comparatively late during postnatal development in monkeys (Goldman- Rakic, 1987). Such late postnatal myelination is generally believed to occur in the phylogenetically most developed associations regions (Flechsig, 1920), t

\item
only cluster 2 was congruently coupled (across MACM and RSFC) with the amygdala (involved in significance evaluation) and the nucleus accumbens (involved in reward evaluation)
s well as exclusively functionally asso- ciated with facial appraisal. Similarly, the human vPCC was the only PMC region connected to the laterobasal (rather than centromedial or superficial) nuclei group of the amygdala (Bzdok et al., 2013b), which is an amygdalar subregion probably devoted to continuously scanning environmental input for biological significance (Adolphs, 2010; Aggleton et al., 1980; Bzdok et al., 2011; Ghods-Sharifi et al., 2009; LeDoux, 2007).
\end{itemize}

  \item
    vPCC:
the ventral visual stream—the “what” system for object process- ing (Ungerleider and Haxby, 1994; Ungerleider and Mishkin, 1982; Vogt et al., 2006), contrary to the dPCC's conceivable relation to the dorsal “where” system
\item
  dPCC:
This view is in line with the well-known integration of the dPCC in the dorsal visual stream—the “where” system for spatial processing (Ungerleider and Haxby, 1994; Ungerleider and Mishkin, 1982; Vogt et al., 2006), in contrast to vPCC's relation to the ventral “what” system

\item
RSC:
Regarding memory processing, lesions in the RSC, as compared to other PMC regions, is most consistently associated with anterograde and retrograde memory impairments of different types of sensory infor- mation in rabbits (Gabriel and Talk, 2001) and humans (Rudge and Warrington, 1991; Valenstein et al., 1987).
current findings and earlier lesion reports can be parsimoniously reconciled by the previously proposed notion that the RSC mediates between the organism's egocentric (i.e., focused on sensory input) and allocentric (i.e., focused on world knowledge) perspective frames (Burgess, 2008; Epstein, 2008; Valiquette and McNamara, 2007).

\item
BOTH TPJ:


\item
RTPJ:

\item

LTPJ:



\item
  PMC:
  \begin{itemize}
    \item
covert reallocation of spatial attention (Gitelman et al., 1999), mediation between internal and external focus (Leech and Sharp, 2014), computation of environmental statistics (Pearson et al., 2009), and self-referential visuospatial imagery (Cavanna and Trimble, 2006)
  \end{itemize}




\item
HC:
\begin{itemize}
  \item
The HC, in turn, is well known to be involved in memory and spatial navigation in animals and humans (von Bechterew, 1900; Scoville and Milner, 1957; O’Keefe and Dostrovsky, 1971; Maguire et al., 2000).

\item
the GMV of the entorhinal cortex (connectionally and functionally closely coupled with the HC) correlated with social network size (Kanai et al., 2012)


\item 
 In fact, phase-locked hippocampal?<80><93>cortical loops have been proposed t
 formation of mnemonic neuronal representations
 **a large body of animal and human literature relates
hippocampal-prefrontal theta to memory and memory to the DMN**
\end{itemize}
\end{itemize}


\section{Methods}
\subsection{Linear control network model for brain organization}
Consider the following linear time-invariant (LTI) dynamical system as a (toy) model for high-level brain function
\begin{equation}
  \dot{\x}(t) = \A\x(t) + \B\u(t).
  \label{eq:lti}
\end{equation}
Here, the $n$-by-$n$ matrix $\A$ denotes a model of the brain's wiring (for example a resting state connectome computed from an anatomical atlas), while the $n$-by-$k$ ``input matrix'' $\B$ describes which nodes can be controlled by us, an external \textit{controller}, via medical intervention or a careful choice of stimulus presentation, for example.
At time $t \ge 0$, let  the $n$-vector  $\x(t) := (\x_1(t),\ldots,\x_n(t))$ encodes the state of the network (one value for each node). The aim is to supply values of $\u_1(t),\ldots,\u_k(t)$ for $k \le n$ controls as a function of the time $t$,  to take the system from any prescribed initial state $\x(0) = \x^{\text{init}} \in \mathbb R^n$ to any prescribed final state $\x(\tau) = \x^{\text{fin}} \in \mathbb R^n$ in finite time $\tau < \infty$.
When such a controlling is possible, we say that the system $(\A,\B)$ is \textit{controllable}. A precise sufficient and necessary condition for such controllability is the Kalman condition: $(\A,\B)$ is controllable iff the $n \times nk$ \textit{controllability matrix}
\begin{equation}
  \C := (\B|\A\B|\ldots|\A^{n-1}\B)
\end{equation}
has full rank, i.e
\begin{equation}
  rank(\C) = n.
\end{equation}

\paragraph{How many controls do we need at best ?}
In the thermodynamic limit ($n \rightarrow \infty$), statistical physics \cite{Liu2011} gives the extremely good estimate
\begin{equation}
  n_0(\langle k\rangle, \gamma) \approx e^{-\frac{1}{2}\left(\frac{\gamma-2}{\gamma - 1}\right)\langle k \rangle},
\end{equation}
where $\gamma \ge 1$ is the \textit{scale-free} parameter for the node-degree distribution of the network described by $\A$, and $\langle k \rangle$ is the mean degree. Letting $\gamma \rightarrow \infty$, one recovers the Erdos-Renyi value
\begin{equation}
  n_0(\langle k\rangle) = e^{-\frac{1}{2}\langle k\rangle},
\end{equation}
which agrees perfectly with its known analytic value. One identifies two radically different regimes:
\begin{itemize}
  \item the manageable regime $\gamma > \gamma_c := 2$, in which $n_0 < 1$, and so we only need fewer controls than total number of nodes, and
\item the unmanageable regime ``$\gamma \le \gamma_c$'', in which  $n_0 = 1$, where each node must be controlled explicitly.
\end{itemize}

\paragraph{Why linear dynamics ?}
As explained in \cite{Liu2011}, the choice of linear dynamics over a more general nonlinear dynamics can be justified as follows:
\begin{itemize}
  \item  Conclusions drawn from linear dynamics can be
extended to nonlinear systems.
\item If the controllability matrix of the linearized system
has full rank at all points, then it is sufficient for most
systems to say that the actual nonlinear system is
controllable (i.e. small signal model).
\end{itemize}

\paragraph{A note on stability.}
For stability in the LTI model \eqref{eq:lti} and hence in the constrained path integral \eqref{eq:hj} below, a sufficient (and necessary ?) condition is that all eigenvalues of the $A$ have negative real-part. One way to impose this is to add self-loops with a small negative weight.
\paragraph{Meta brain.}

\subsection{Optimal control: an LQR feedback controller}
We propose to use a linear quadratic regulator (LQR) for the feedback controller. Thus, consider the time-varying \text{value function} $V: [0, \tau] \times \mathbb R^n \rightarrow \mathbb R$, defined by the following Hamilton-Jacobi cost-to-go
\begin{equation}
  \begin{split}
    &V(t, \z) := \min_{\u} \frac{1}{2}\x_{\text{fin}}^T\Q_{\text{fin}}\x_{\text{fin}} + \int_{0}^\tau\left(\frac{1}{2}\x(t)^T\Q\x(t) + \frac{1}{2}\u(t)^T\R\u(t)\right)dt,\\
    &\text{subject to } \x(t) = \z, \dot{\x}(t) = \A\x(t) + \B\u(t),
  \end{split}
  \label{eq:hj}
\end{equation}
where the matrices $\Q$ and $\R$, precised by design considerations and subject to meta-optimization, are restricted to be positive semi-definite and positive definite, respectively. A classical calculation (reminiscent of the \textit{Pontryagin minimization principle}) reveals that the optimal feedback control in \eqref{eq:hj} is given by
\begin{equation}
  \u(t) = -\K(t)\x(t),
\end{equation}
where
\begin{equation}
  \K(t) := \R^{-1}\B^T\P(t)\text{ (Kalman gain matrix)}
\end{equation}
and the time-varying positive semi-definite matrix $\P(t)$ solves following differential Riccati equation (DRE)
\begin{equation}
\begin{split}
&-\dot{\P}(t) = \A^T\P(t) + \P(t)\A - \P(t)\B\R^{-1}\B^T\P(t) + \Q\\
&\text{subject to }\P(\tau) = \Q_{\text{fin}}.
\end{split}
\end{equation}
\subsection{Minimal control energy controller}
\subsection{Related works}
The model proposed in \cite{betzel2016} can be cast in the form \eqref{eq:hj}, with the particular choice $\Q = \textbf{I} = \rho^{-1}\R$ and $\Q_{\text{fin}} = \textbf{0}$, but with a rather ad-hoc handle on stability issues and choice driver nodes...

\subsection{A thermodynamic model for bounded rationality, aka robust optimality}
\begin{itemize}
  \item Recall that an agent is said to have \textit{bounded rationality} if they must take into account the cost of finding solutions to problems, and not just the utility of the final state.
  \item For example, consider an agent that must operate under a limited lifetime and/or computation cost.
  \item This is in contrast to agents with \textit{unbounded rationality} considered in classical game theory.
    \end{itemize}

\paragraph{Utility functions and conjugate pairs.}
  Let $(\Omega, \mathcal F, \P)$ be a probablity space. A function $\U: \mathcal F \rightarrow \mathbb R$ is said to be a \textit{utility function} for this space if the conditional utility $\U(A|B) := \U(A \cap B) - \U(B)$ has the following propertites:
  \begin{itemize}
  \item additivity: $\U(A_1 \cap A_2 | B) = \U(A_1|B) + \U(A_2|B)$, for all events $A_1, A_2, B \in \mathcal F$.    
  \item statistic: there exists a function $f_{\U} :\mathbb R_+ \rightarrow \mathbb R$ such that $\U(A|B) = f(\P(A|B))$, for all events
    $A,B \in \mathcal F$.
  \item monotonicity: $f_{\U}$ is strictly increasing.
    \end{itemize}

\begin{theorem}
  The only functions $f: \mathbb R_+ \rightarrow \mathbb R$ which is such that $\U(A|B) \equiv f(\P(A|B))$ any probability space $(\Omega, \mathcal F, \P)$ and utility function $\U$ thereupon are of the form
  \begin{equation}
    f = \alpha \log(.),
    \label{eq:boltzmann}
  \end{equation}
  where $\alpha > 0$.
\end{theorem}

\textbf{XXX: equation \eqref{eq:boltzmann} above looks like Boltzmann's formula (on his gravestone...)!}

Such $\U$ and $\P$ are said to form a \textit{conjugate pair} at temperator $\alpha$.


\paragraph{Example.}
Given utility function $U$ a probability space $(\Omega, \mathcal F, *)$, the \textit{Gibbs measure} at temperature $\alpha > 0$ and energy levels $(-\U(\omega))_{\omega \in \Omega}$ is defined to be probability measure (on thesame measurable space)
  \begin{equation}
    \P_{\U}(A) = \sum_{\omega \in A}\frac{1}{Z(\alpha)}\exp\left(\frac{1}{\alpha}\U(\omega)\right), \; \forall A \in \mathcal F.
  \end{equation}
$Z(\alpha)$ is a normalization constant such that $\P_{\U}(\Omega) = 1$.  It's not hard to see that $\U$ and $\P_{\U}$  form a conjugate pair.

  \paragraph{Free-utility functional.}
    Let $(\U, \P)$ be a conjugate pair at temperature $\alpha > 0$  on a measurable space $(\Omega, \mathcal F)$. Given another probability measure $\P'$ on the same space, define it's \textit{free utility} as
    \begin{equation}
      J(\P'|\U, \P) = \mathbb E_{\P'}(\U) + \alpha \mathbb H(\P'),
    \label{eq:free_u}
    \end{equation}
    where $\mathbb H(\P') := -\sum_{\omega \in \Omega}\P'(\omega)\log(\P'(\omega))$ is the entropy of $\P'$.

  It's not difficult to show that
  \begin{equation}
    J(\P'|\U,\P) \le J(\P|\U,\P) = \sum_{\omega \in \Omega}\U(\omega) =: \U(\Omega).
  \end{equation}
  In particular, if $\P = \P_{\U}$ the Gibbs measure, then the upper bound above reduces to the \textit{log-partition function}
  \begin{equation}
    J(\P'|\U,\P) \le \U(\Omega) = -\alpha \log\left(\sum_{\omega \in \Omega}e^{\frac{1}{\alpha}\U(\omega)}\right).
    \end{equation}

  \paragraph{The free-energy / utility principle.}
  We are now in shape to introduce the notion of free-energy for transition of priors, and a variational principle for optimizing it. Consider thus an initial system described by a conjugate pair $(\U_{\text{ini}}, \P_{\text{ini}}) \rightarrow \P_{\text{fin}}$ at temperature $\alpha > 0$. We want to transform this to a new one by adding constraints represented by the utility function $\delta \U$.  The resulting system has final utility $\U_{\text{fin}} = \U_{\text{ini}} + \delta\U$. The difference in free-utility is then
  \begin{equation}
    \delta J = J_{\text{fin}} - J_{\text{ini}} = \underbrace{\mathbb E_{\P_{\text{fin}}}(\delta \U)}_{\textbf{expected gain in utility}} + \alpha \underbrace{D_{\text{KL}}(\P_{\text{ini}}\|\P_{\text{fin}})}_{\textbf{complexity of change}},
    \label{eq:free}
  \end{equation}
  where $D_{\text{KL}}(\P_{\text{ini}}\|\P_{\text{fin}})$ is the Kullback-Leibler divergence.
  In the above formula, we've extensively used the fact that $(\U_{\text{ini}}, \P_{\text{ini}})$ is a congugate pair and so $\U_{\text{ini}}(\omega) \equiv \alpha \log(\P_{\text{ini}}(\omega))$ by virtue of \eqref{eq:boltzmann}.
  The two terms in \eqref{eq:free} (expected gain in utility or negative workdone, and the complexity of the transition) 
  
\section{Experimental Results}
\paragraph{Serial versus parallel structure discovery and classification.}


\section{Discussion and Conclusion}



\paragraph{Acknowledgment}
% {\small The research leading to these results has received funding from the
% European Union Seventh Framework Programme (FP7/2007-2013)
% under grant agreement no. 604102 (Human Brain Project).
% Further support was received from
% the German National Academic Foundation (D.B.).
% }

\small
\bibliographystyle{splncs03}
\bibliography{nips_refs}

\end{document}
