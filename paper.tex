\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{mdframed}
\usepackage{bbm}
\usepackage{algorithm,algorithmic}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{bbm}
\usepackage[titletoc]{appendix}
\usepackage{wrapfig}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{ulem}
\usepackage{multirow}

\def\B#1{\bm{#1}}
%\def\B#1{\mathbf{#1}}
\def\trans{\mathsf{T}}

%\renewcommand{\labelitemi}{--}

\newtheorem{theorem}{Theorem} \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}{Remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{A Computational Account of Default-Mode Function\\by Control Theory and Reinforcement Learning}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\Prox}{Prox}
\DeclareMathOperator{\im}{im}

% macros from michael's .tex
\DeclareMathOperator{\dist}{dist} % The distance.
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\argmax}{argmax}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\abs}{abs}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}

\def\Id{\mathbf{I}}
\def\1{\mathbf{1}}
\def\X{\mathbf{X}}
\def\U{\mathbf{U}}
\def\V{\mathbf{V}}
\def\v{\mathbf{v}}
\def\u{\mathbf{u}}
\def\z{\mathbf{z}}
\def\Y{\mathbf{Y}}
\def\A{\mathbf{A}}
\def\B{\mathbf{B}}
\def\C{\mathbf{C}}
\def\N{\mathbf{N}}
\def\R{\mathbf{R}}
\def\Q{\mathbf{Q}}
\def\P{\mathbf{P}}
\def\K{\mathbf{K}}
\def\a{\mathbf{a}}
\def\b{\mathbf{b}}
\def\s{\mathbf{s}}
\def\x{\mathbf{x}}

\newcommand{\suggestadd}[1]{{\color{blue} #1}}
\newcommand{\suggestremove}[1]{{\color{red} \sout{#1}}}

% \nipsfinalcopy % Uncomment for camera-ready version
\nipsfinaltrue
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\author{Elvis Dohmatob, (Bert Kappen), Danilo Bzdok\\
  INRIA, Parietal team, Saclay, France\\
  CEA, Neurospin, Gif-sur-Yvette, France\\
  firstname.lastname@inria.fr}

\maketitle


\begin{abstract}

the DMN is often proposed to be dedicated to continuous auto- biographical memory retrieval, environmental assessment, emotion ap- praisal, and reward contingency evaluation when letting the mind go.

Constantly tracking and predicting changes in a variable environment is believed to then shape the internal milieu and upcoming external behav- ior adaptively

The model reinterprets many known effects

If this computational models hold some truth in them, the DMNs conceivable key role in the continuous environmental tracking in a generative, integrative process might explain both its highest energy consumption in the brain and its intimate coupling with conscious awareness.

network that might be involved in the automated prediction of social events that modulate behavior

We focus not on normative models (that describe what the brain does), but on process models (that describe how the brain does it)

\end{abstract}

% official NIPS keywords
\textbf{\\keywords}: Systems Biology, Cognitive Science, Autonomous Learning Systems

\tableofcontents

\section{The Default-Mode Network}
%
When left unperturbed, the human brain is not at rest. Rather, the brain continues to metabolize large quantities of oxygen and glucose energy to maintain inter-neuronal information transfer in the absence of an externally structured task (Bzdok and Eickhoff, 2016a). This baseline energy demand is subject to surprisingly little modulations due to the cognitive load posed by environmental challenges. What has early been described as the "stream of consciousness" in psychology (James, 1890).
%
A few years ago, the so-called "default mode network" was discovered entirely by accident (Shulman et al., 1997). A coherent set of brain regions consistently increased in neural activity during stimulus-independent thought, which was proposed to reflect the neural correlates underlying unfocused everyday mind wandering (Raichle et al., 2001). That is, in the beginning of the 21st century, brain imaging was the first technology to allow for the discovery of a coherent brain network that subserves a set of baseline mental activity (Bzdok et al., 2012; IBzdok et al., 2015).
%
15 years ago neuroscientists have discovered an energy-demanding brain network with unique properties. The "default-mode network" (DMN) appeared exclusive in task-induced deactivation during various psychological experiments. It was later argued to be systematically anti-correlated with brain regions that subserve task performance. Today, many authors speculate that the DMN implements continuous thinking about others’ and one’s own mind states, as well as adaptive envisioning of past, hypothetical, and future events. This network might have emerged to continuously predict environmental events using mental imagery as an evolutionary advantage.
%
Since 2001, the neurobiological properties of the default mode network have been investigated and reported in more than 3,000 neuroimaging publications 
The DMN was initially believed to represent the neural correlates of unconstrained mind-wandering because of its pervasively observed activity decrease during a large array of tasks. This processing of unknown information categories in the DMN has been argued to mediate an evolutionarily conserved function for the individual. This is all the more likely because the DMN contains the two biggest hotspots of energy consumption in the entire central nervous system. DMN activity also persists to a substantial degree during the early stages of sleep (Horovitz et al., 2008) and under anesthesia (Greicius et al., 2008). However, information processing in the DMN has also repeatedly been shown to impact human behavior. Goal-directed task performance improves with decreased activity in default-mode areas (Weissman et al., 2006) and increased DMN activity is linked to more task-independent, potentially disturbing thoughts (Mason et al., 2007). 
%
the DMN is likely to control the interplay between perception–action cycles and mental imagery (Bzdok et al., 2013a; Bzdok et al., 2013b). In particular, the DMN is likely to subserve a computational mechanism by its connections to highly associative brain areas that is key for human thought across time, splace, and content domains at the interface of external world and self (IBzdok et al., 2015).
%

hierarchically deep models of the world

sensory exchanges with the world

show how a formal approach can provide generic explanations for psycho- pathology that are physiologically grounded

quantitative (and parametric) characterisations offered by computational

d Biological systems are homeostatic (or allostatic), which
means that they minimize the dispersion (entropy) of their
interoceptive and exteroceptive states.
d Entropy is the average of surprise over time, which means
that biological systems minimize the surprise associated
with their sensory states at each point in time.
d In statistics, surprise is the negative logarithm of B

perception as hypothesis testing 

Consider an organism that, in their present situation, is confronted by several choices of what to do next. Being able to accurately and richly mentally enact possible future states before making a decision would help to evaluate the desirability of different outcomes and also the planning processes needed to make them happen.

 the use of this constructive process goes far beyond simply predicting the future, to the general evaluation of fitness for purpose

scene construction processes when envisioning past, fictitious, and future events (Hassabis et al., 2007; Spreng et al., 2009).

It was observed that the more external stimuli are predictable, the more reflection processes become detached from the actual sensory environment and the more stimulus-independent, self-focused thoughts occur (Mason et al., 2007).

\begin{itemize}
  \item includes brain regions with highest baseline energy consumption in humans
  \item most active in non-disturbed mind-wandering without external influence
  \item tends to deactivate when humans engage in goal-direct tasks
  \item fluctuations in the DMN are related to lapses during and performance in
  such externally structured/focused tasks
  \item includes brain regions that come online first when waking up from
  anesthesia
  \item its network nodes are late to myelinate, an indicator of cognitive sophistication
  \item includes the most advanced processes hierarchies and has
  no direct connections with sensory regions processing external input
  \item the DMN's conceivable key role in the continuous environmental
  tracking in a generative, integrative process might explain both its highest energy consumption in the brain and its intimate coupling with conscious awareness
  \item Indeed, patients with right IPL (=DMN) damage have particular difficulties
  with multistep actions (Hartmann et al. 2005)
  and with imagined action (Sirigu et al. 1996).
  \item Lesion of the hippocampus, feeding memory and spatial information, to the
  DMN impairs future and hypothetical thinking (cf. Hassabis PNAS)

  \item
  autobiographical memory sup- plies numerous building blocks of social semantic knowl- edge (Bar 2007; Binder et al. 2009). These isolated conceptual scripts may be reassembled to enable the fore- casting of future events (Tulving 1983, 1985; Schacter et al. 2007). Similar brain mechanisms in remembering past episodes and envisioning future circumstances is supported by their engagement of identical brain areas, as evidenced by a quantitative meta-analysis (Spreng et al. 2009). Moreover, retrograde amnesic patients were repor- ted to be impaired not only in prospection but also in imagining novel experience (Hassabis et al. 2007). These findings suggest a single neural network for mentally constructing plausible semantic scenarios of detached sit- uations regardless of temporal orientation (Buckner and Carroll 2007; Hassabis and Maguire 2007). Indeed, con- struction of detached probabilistic scenes has been argued to influence ongoing decision making by estimating out- comes of behavioral choices (Boyer 2008; Suddendorf and Corballis 2007; Schilbach et al. 2008b). 
  \item
  DMN exists in monkeys [73] and rats [74]. 
  \item clinical research has corroborated default-mode network dysfunction in various psychiatric and neurological disorders
\end{itemize}

The DMN poses an unprecedented challenge to our neuroscientific understanding and methodological inventory.

Despite ramifications in health and disease, the functional role of the DMN poses an unprecedented challenge to the conventional interpretation strategies and existing methodological arsenal in the neurosciences.

Represents the physiological and pathological instantiation of a human beings' default mental repertoire, the nature of which remains largely obscure.

The DMN has now urged major attention in the neuroscientific community (Raichle et al., 2001, >6600 citations). 



\section{Control Theory and Reinforcement Learning}
\paragraph{Control Theory.}
\begin{itemize}
\item mathematically formalized dynamics systems with input, output and
feedback loops that produce error signals for adaptation
\item typically realized by (non-linear) differential equations
\item has been used to describe neural systems in the past
\item gradient update = learn/adapt system dynamics by error occurrence
\item related to notions of game theory
\item switching between states -> typically reduces to a sequential processing model
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item policy: action to take given a state
\item value: prediction of future reward
\item model: predict what the environment will do next
\item model-baseed RI learning: we try to understand the environment; it is initially unknown
\item special to RL: exploitation vs. exploration
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\item Tenenbaum2011Science: Much recent work points to Monte Carlo or stochastic sampling– based approximations as a unifying framework for understanding how Bayesian inference may work practically across all these levels, in minds, brains, and machines (70–74).
\end{itemize}






\section{The Neurobiological Properties of the Default-Mode Network}
 involvement of the PMC across the boundaries of classical cognitive domains
mPFC and PCC = highest metabolic consumption in the brain/highest level of basal glucose energy consumption in humans

PFC
Patients with prefrontal lesions have problems in adapting to novel situations and stimuli
Stuss, D. T. \& Benson, D. F. The Frontal Lobes (Raven, New York, 1986).

vmPFC regions respond more to the value difference that will be acted on in the current trial (executed in red), and dmPFC to the currently irrelevant value difference (modeled in blue) {Nicolle, 2012 \#3750} individual. Instead activity in vmPFC reflects a choice preference that is executed and rostral dmPFC a choice preference that is modeled. Thus, dorsal regions of rostral mPFC contain value representations in the frame of reference of a modeled (as opposed to an actuated) preference irrespective of whether this applies to another’s or to one’s own likely actions and goals. Likewise, ventral mPFC contains a representation of value in the frame of reference of an executed choice, even if this executed choice reflects one’s own or another’s preferences. dmPFC that reflects the values and preferences of another individual (here temporally discounted at a rate specific to the individual), even when they are not directly relevant to the task at hand. Critically, we also show this activity. While the simplest interpretation of this effect is that the region is simulating one’s own, currently irrelevant, preferences an alternative possibility is that the activity is projec- ting one’s own values into the mind of the partner, while simu- lating the partner’s choices. In essence, estimating the extent to which my own values would influence my partner, if they were making the choice. This iterated reasoning would be.

mechanistic relevance of each node -> we deconstruct

DMN function has been linked to the recollection of past episodes and the simulation of future episodes

Simony 2016
This implies that the processing timescale of the DMN is longer than the length of single paragraphs (B40s) and that information accumulated from prior paragraphs can affect ongoing processing in this system


\begin{itemize}
  \item
    vmPFC:
    \begin{itemize}
    \item
the vmPFC sub- serves predominantly non-ambiguous subjective-value-related evaluative processes driven by bottom-up pathways
memory-informed reward and risk estimation of self-relevant environmental stimuli.
\item
the vmPFC might be more closely associated with orches- trating adapted behavior by bottom-up-driven processing of “what matters now”

\item
the vmPFC to monitoring others’ (Lotze et al., 2007) and one’s own (Lane et al., 1997; Phan et al., 2004) emotional responses, that is, other’s (external) emotional reac- tions and one’s own (visceral) arousal. Such real or imagined bodily states, believed to be represented in the vmPFC, proba- bly operate as a bioregulatory disposition governing cognition and decision making (Damasio, 1996; Nauta, 1971), in line with the vmPFC’s functional association with general cognition and reward processing.

\item
Most importantly, independent whole-brain analyses from structural neuroimaging studies related the gray-matter volume (GMV) of the vmPFC to indices of social competence and social network complex- ity in both humans and monkeys (Lebreton et al., 2009; Powell et al., 2010; Lewis et al., 2011; Sallet et al., 2011). To our knowl- edge, none of these four correlations have been found yet for the dmPFC. Consequently, vmPFC, rather than dmPFC, anatomy appears to predict an individual’s social behavioral dispositions and social network properties,

\item
With respect to our seeds, inter-individual differences in social skills or social networks were most often related to morphological differences in the human and monkey vmPFC, in stark contrast to the dmPFC

\item
self-related behavior guided by stimulus evalua- tion and reward-learning, a voxel-based lesion-symptom map- ping (VLSM) study in 344 neurological patients demonstrated functional-anatomical specificity of the vmPFC for value-based decision-making (Gläscher et al., 2012).


\item
As to the vmPFC subnetwork, the GMV of the vmPFC and VS correlated with indices of social reward attitudes and behavior (Lebreton et al., 2009), concur- ring with vmPFC’s relation to the NAc and reward-related tasks.

\item
In studies of decision making and neuroeconomics, ventromedial prefrontal cortex (vmPFC) con- sistently reflects an individual’s subjective valuation (Behrens et al., 2008; Boorman et al., 2009; Knutson et al., 2005; Plass- mann et al., 2007). By contrast, its dorsomedial neighbor (rostral

\item
NAC was proposed to subserve model-free reinforcement learning in humans
(O'Doherty 2015)

\item
In both MACM and RS analy- ses, the vmPFC was more strongly connected with the nucleus accumbens (NAc), hippocampus (HC), posterior cingulate cor- tex (PCC), and retrosplenial cortex (RSC)
In both functional decoding analyses, the vmPFC was selectively associated with reward related tasks

\item
processing approach- and avoidance-relevant stimuli

\item
Glaescher: lesions -> value-based decision making  in 344 individuals
based decision-making, which included the orbitofrontal, ventro- medial, and frontopolar cortex.

\item
Indeed, the vmPFC, but not dmPFC, has been observed to have monosynap- tical connections with the ventral striatum (VS, which anatom- ically includes the NAc) in axonal tracing studies in monkeys (Haber et al., 1995; Ferry et al., 2000).
This is consistent with our results and probabilistic diffusion tensor imaging (DTI) trac- tography in humans and monkeys (Croxson et al., 2005) that quantified the VS to be substantially more likely connected to the vmPFC than dmPFC in both species.

\item
the vmPFC is preferentially connected with limbic and reward-related medial brain areas.
The NAc is thought to be linked to reward mechanisms that may not only modulate motivated behavior towards basic survival needs

\item
Such real or imagined bodily states, believed to be represented in the vmPFC, proba- bly operate as a bioregulatory disposition governing cognition and decision making (Damasio, 1996; Nauta, 1971),

\item
\end{itemize}



\item
  dmPFC:
  \begin{itemize}
    \item
dmPFC subserves predominantly ambiguous amodal metacogni- tive processes driven by top-down pathways

\item
A class of neurons in macaque dorsomedial frontal cortex, including the presupplementary area, responds preferentially to the actions that another macaque makes rather than their own actions (Yoshida et al., 2011)
Many of the same neurons differentiate between another macaque’s actions that were unsuccessful, because the circumstances changed, and actions that were unsuccessful because the other macaque did not make the best choice given the circum- stances. The macaques adjusted their own subsequent actions in different ways after these two types of obser- vations. There is also activity in human dorsomedial prefrontal cortex that reflects expectations about what an observed person will do and errors in such predictions (Suzuki et al., 2012; van Schie et al., 2004)


\item
largely sensory-independent, highly abstract (hence, less tangible) processes across time, space, and content domains.
might be top-down modulated by more dmPFC subserved higher reflective and hypothetical processing.
consistent with present functional decoding, neural activity in the dmPFC, rather than vmPFC, has been con- sistently interpreted to underlie inference, representation, and assessment of one’s own and others’ mental states in functional neuroimaging research

\item
 dmPFC (but not vmPFC) activity was related to the proficiency decline of mental state inference in elderly (Moran et al., 2012), cognitive regulation of one’s own emotional states (Ochsner et al., 2004b) and inference of another person’s emotional states (Ochsner et al., 2004a), as well as self-reported (Wagner et al., 2011) and experimentally measured (Zaki et al., 2009) proficiency in emotional state inference.

 \item
Thus, mental state inference necessarily relies on the generation of probabilistic internal information. Supported by dmPFC’s functional association with episodic memory retrieval, such prima vista non-mnemonic construction processes are likely to be subserved by the neural network underlying retrieval of past and imagination of future scenes as indicated by recent neu- roimaging experiments and meta-analyses

\item
congruently characterizes the dmPFC as a “mental sketchpad” (Goldman-Rakic, 1996) potentially impli- cated in modeling and binding plausible self- and other-related scenarios instructed by semantic concepts

\item
 sensory-independent de novo generation of mean- ing representations can only be expected from highly associative, integrative brain areas such as those of the dmPFC subnetwork

\item
the dmPFC subserves a domain-independent neural process

\item
the present results support the dmPFC’s possible involvement in domain-overarching computational mechanisms given its connections to highly associative brain areas and function- ally relation to different complex psychological processes.

\item
the dmPFC was more strongly connected with the inferior frontal gyrus (IFG), temporo-parietal junction (TPJ), and middle temporal gyrus (MTG)

\item
Concluding from previous and present connectivity findings, the dmPFC is preferentially connected with high association and heteromodal cortical areas of the lateral frontal, temporal, and parietal lobe.

\item
it is interesting to note that the vmPFC is more strongly con- nected to medial components of the default mode network (i.e., HC, PCC, RSC), whereas the dmPFC is more strongly con- nected to its lateral components (i.e., IFG, TPJ, and MTG). This dmPFC subnetwork was repeatedly related to self-focused reflec- tion (Andrews-Hanna et al., 2010), contemplation of others’ (Mar, 2011) and one’s own (Lombardo et al., 2009) mental states, mental navigation of the body in space (Maguire et al., 1997), semantic processing (Binder et al., 2009), as well as scene con- struction processes when envisioning past, fictitious, and future events (Hassabis et al., 2007; Spreng et al., 2009; Bzdok et al., 2013).


\item
a VLSM study on disturbed sleep (i.e., a state of mind independent of sensory stimulation but dependent on internally generated informa- tion) exclusively identified the dmPFC (Koenigs et al., 2010).
-> experience replay during sleep

\end{itemize}

  \item
    PCC (gradients):
    \begin{itemize}
      \item rewards (exploitation) and gathering information about alter- native options (exploration)
Such strategic decisions should incorporate not only recent reward history, but also opportunity costs and environmental statistics

\item
covert reallocation of spatial attention (Gitelman et al., 1999), mediation between internal and external focus (Leech and Sharp, 2014), computation of environmental statistics (Pearson et al., 2009), and self-referential visuospatial imagery (Cavanna and Trimble, 2006)


\item
single-cell recordings in the monkey PCC demonstrated this brain region's sensitivity to subjective target utility (McCoy and Platt, 2005) and integration across individual outcomes in decision making (Pearson et al., 2009).
ng attraction or aversion to options with uncertain or risky rewards
. CGp activation was better predicted by the
subjective salience of a chosen target than by its actual value.

\item
experimental psychologists and behavioral ecologists
have long argued that decision making depends on the conversion
of external variables into a common internal currency of value.

\item
electrophys- iological research in animals implicated the PCC in strategic selection (Pearson et al., 2009), risk assessment (McCoy and Platt, 2005), and outcome-contingent behavioral modulation (Hayden et al., 2008), while the RSC was implicated in nav- igation and approach-avoidance behavior (Vann et al., 2009).

\item
(McCoy and Platt, 2005):
t internal representations of value lie at the very core of
decision making,
visual gambling task used in the current study affords a unique
opportunity to examine neural activity under conditions in which
subjective value, but not objective value, varied, as indicated by
subjects’ choices
-> value matrix is not the same in each agent
h the direction of impending
Our data extend those
findings, demonstrating a direct relationship between subjective preferences
for uncertain rewards, or the opportunity to harvest a
relatively large reward, and the activity of neurons thought to participate
in the allocation of attention
movement, as shown previously24,30, and the uncertainty of rewards
associated with this movement
CGp appears to carry spatial information that is scaled by
subjective preferences for particular patterns of reward outcome.
Our data indicate that CGp
neurons signal subjective biases for uncertain rewards (or, perhaps, the
potential to receive a large reward) rather than objective target value.
the spatial sensitivity of CGp neurons was enhanced under
conditions of high risk.
-> delay discounting / non-immediate reward -> reinforcement learning

\item
Pearson2009:
balance. Here we show that CGp neurons distinguish be- tween exploratory and exploitative decisions made by mon- keys in a dynamic foraging task.
 option switching [11] and integrate this information across multiple trials [11], but the present

 \item
 Together, these results invite the hypothesis that CGp is part of a network that monitors the outcomes of individual deci- sions and integrates that information into higher-level strate- gies spanning multiple choices

 \item
keys in a dynamic foraging task. Moreover, firing rates of these neurons predict in graded fashion the strategy most likely to be selected on upcoming trials. This encoding is distinct from switching between targets and is independent of the absolute magnitudes of rewards. These observations implicate CGp in the integration of individual outcomes across decision making and the modification of strategy in dynamic environments.
recorded the activity of single cingulate cortex (CGp) neurons

\item
choosing among multiple tar-
gets whose relative values changed dynamically,
neurons in posterior cingulate cortex signaled the distinction between trials on which monkeys pursued an exploratory rather than an exploitative strategy.
**learn its current value and integrate this information with their statistical knowledge of the environment to predict its relative value on upcoming trials.**


\item
Hayden2008: adapativity of subjective reward schedules tht impact the action choices
 lesion (Gabriel, 1990) studies strongly implicate CGp in working mem- ory, attention, and general arousal (Raichle and Mintun, 2006)— all processes that contribute to adaptive decision making. -> gradient defect

\item
corded activity of single neurons in monkeys per- forming a gambling task in which the reward outcome of each choice strongly influenced subsequent choices.
choices. We found that CGp neurons signaled reward outcomes in a nonlinear fashion and that outcome- contingent modulations in firing rate persisted into subsequent trials. Moreover, firing rate on any one trial predicted switching to the alternative option on the next trial. Finally, microstimulation in CGp follow- ing risky choices promoted a preference reversal for the safe option on the following trial. Collectively, these results demonstrate that CGp directly contrib- utes to the evaluative processes that support dynamic changes in decision making in volatile environments.

\item
 these observations suggest the hypothesis that CGp contributes to the integration of actions and their out- comes and thereby influences subsequent changes in behavior.
 We confirmed a causal role for CGp in outcome evaluation and behavioral adjustment by showing that microstimulation following the most desired reward out- come increased the likelihood of exploring the alternative on the next trial.

 \item
signal decision outcomes in a nonlinear fashion, maintain this information in a buffer between trials, and predict future changes in behavior. Moreover, microstimulation in CGp promotes explo- ration of the previously antipreferred option.

\item
highlight the dynamic nature of information processing in CGp, which is not restricted to any single epoch or aspect of task performance but instead continuously adapts to changes in both the external environment and internal milieu.


\item
(Patho-)Physiologically, meta- bolic fluctuations in the human PMC have been closely related to vari- ous instances of altered conscious awareness, including anesthesia (Fiset et al., 1999), sleep (Maquet, 2000), and restoration from vegeta- tive states (Laureys et al., 1999).

  \item
Electrophysiologically, gamma band re- cordings in humans (Dastjerdi et al., 2011) and single-cell recordings in monkeys (Hayden et al., 2009) revealed activity reductions in the PMC during attentionally demanding tasks compared to rest.

\item
 have long been speculated to reflect constant contemplation of (external) environment and (internal) memory

 \item
   xons in parts of the PMC myelinate comparatively late during postnatal development in monkeys (Goldman- Rakic, 1987). Such late postnatal myelination is generally believed to occur in the phylogenetically most developed associations regions (Flechsig, 1920), t

\item
only cluster 2 was congruently coupled (across MACM and RSFC) with the amygdala (involved in significance evaluation) and the nucleus accumbens (involved in reward evaluation)
s well as exclusively functionally asso- ciated with facial appraisal. Similarly, the human vPCC was the only PMC region connected to the laterobasal (rather than centromedial or superficial) nuclei group of the amygdala (Bzdok et al., 2013b), which is an amygdalar subregion probably devoted to continuously scanning environmental input for biological significance (Adolphs, 2010; Aggleton et al., 1980; Bzdok et al., 2011; Ghods-Sharifi et al., 2009; LeDoux, 2007).

\item Bálint's syndrome: neurological disorder of conscious
awareness resulting from damage in bilateral parietal cortex;
"psychic paralysis of gaze", that is, the inability for internally
motivated, targeted saccades hindering fixation of currently not
attended features in the field of view (i.e., oculomotor apraxia).
unable to bind various individual features of the visual
environment into an integrated whole (i.e., simultanagnosia)
as well as unable to navigate hand movement to a targeted
object helped by vision (i.e., optic ataxia).
difficulty avoiding running into objects placed ahead;
challenged in estimating distances as well as perceiving
spatial depth, object sizes and object orientation


  \item
    vPCC:
the ventral visual stream—the “what” system for object process- ing (Ungerleider and Haxby, 1994; Ungerleider and Mishkin, 1982; Vogt et al., 2006), contrary to the dPCC's conceivable relation to the dorsal “where” system
\item
  dPCC:
This view is in line with the well-known integration of the dPCC in the dorsal visual stream—the “where” system for spatial processing (Ungerleider and Haxby, 1994; Ungerleider and Mishkin, 1982; Vogt et al., 2006), in contrast to vPCC's relation to the ventral “what” system
\end{itemize}



\item RSC:
  \begin{itemize}
\item
Regarding memory processing, lesions in the RSC, as compared to other PMC regions, is most consistently associated with anterograde and retrograde memory impairments of different types of sensory infor- mation in rabbits (Gabriel and Talk, 2001) and humans (Rudge and Warrington, 1991; Valenstein et al., 1987).
current findings and earlier lesion reports can be parsimoniously reconciled by the previously proposed notion that the RSC mediates between the organism's egocentric (i.e., focused on sensory input) and allocentric (i.e., focused on world knowledge) perspective frames (Burgess, 2008; Epstein, 2008; Valiquette and McNamara, 2007).

\item
the left and right TPJ further differ according to their cytoarchitectonic borders and gyral pattern (Caspers et al., 2008; Caspers et al., 2006)

\item
Neuroscientific investigations on hemispheric specialization have converged to the left cerebral hemisphere as dominant for language functions (Broca 1865, Wernicke 1874, Lichtheim 1885) and the right hemisphere as dominant for attention functions (Gazzaniga, Bogen et al. 1965, Sperry 1982, Stephan, Marshall et al. 2003). 
  \end{itemize}


  \item
    RTPJ:
    \begin{itemize}
\item
Corbetta2008:
Although both attentional networks have been most exten- sively investigated in vision, the available evidence indicates a supramodal function (Driver and Spence, 1998; Macaluso et al., 2002). The ventral network (right TPJ, right IFG) registers salient events in the environment not only in the visual but also in the auditory and tactile modalities (Downar et al., 2000)
Several lines of evidence indicate that two cortico-cortical neural systems are involved in attending to environmental stimuli (Corbetta and Shulman, 2002). A dorsal frontoparietal network. A second system, the ventral frontoparietal network, is not ac- tivated by expectations or task preparation but responds along with the dorsal network when behaviorally relevant objects (or targets) are detected (Corbetta et al., 2000). Both dorsal and ventral networks are also activated during reorienting, with en- hanced responses during the detection of targets that appear at unattended locations. For example, enhanced responses are observed when subjects are cued to expect a target at one location but it unexpectedly appears at another (i.e., ‘‘invalid’’ targets in the Posner spatial cueing paradigm)
or when a target appears infre- quently, as in ‘‘oddball’’ paradigms.

Intimately related to prediction error signaling:
An early theory of how the two networks interact (Corbetta and Shulman, 2002) proposed that when attention is reoriented to a new source 
of information (stimulus-driven reorienting), output from the ven- tral network interrupts (as a ‘‘circuit breaker’’) ongoing selection in the dorsal network, which in turn shifts attention toward the novel object of interest.

relevance is the critical factor that determines whether an object activates the ventral network (Downar et al., 2001). The ventral network might be considered a prime candi-date for mediating orienting to salient but unimportant stimuli, i.e., exogenous attention (Posner and Cohen, 1984), be- cause under passive conditions it is highly responsive to distinctive sensory
events in all modalities (Downar et al., 2000). The ventral network is well activated by stimuli that are important, even if they are not very distinctive. 
CURRENT OPINION: VA network does underlie  stimulus-driven reorienting to environmental stimuli based on their task relevance. An important conclusion from these neuroimaging studies is that the psychological dis- tinction between exogenous and endogenous orienting (Jo- nides, 1981) may not map onto different neural systems. "changing the control of behavior from one environ- mental input to another". Similar reorienting mechanisms may also be involved in shifting from a broad range of ‘‘internally directed’’ processes in order to deal with environmental events, as when interrupting memory retrieval (‘‘did I lock the car door?’’) to respond to a sudden stimulus (‘‘is that my cell phone ring- ing?’’). -> medites between the Default-Mode function and other more environmentally directed processing goals.
inducing network reconfiguration

\item
blanke:
the core region of the human vestibular cortex is situated close to the angular gyrus10. It is possible that the experience of dissociation of self from the body is a result of failure to integrate complex somatosensory and vestibular information.
Initial stimulations (n 3; 2.0–3.0 mA) induced vestibular responses, in which the patient reported that she was “sinking into the bed” or “falling from a height”.

\item
high-level social cognition also engenerded expectation violations
-> that's why coincides with "agency" meta-analytic location
(Decety 2007):
suggest that activation in the TPJ during social cognition may therefore rely on a lower-level computational mech- anism involved in generating, testing, and correcting internal predictions about external sensory events.


\item
Sridharan: RTPJ involved in bottom-up saliency detection


\item
Corbetta2002:
 We suggest that the TPJ is also strongly engaged by stimuli that are behaviourally relevant but require a change in the current task set. 
 -> exogeneously induced state transition?
 <=> MCMC in HC / PCC -> slow? endogeneous changes in state transitions by the policy and value matrices
 For example, the alarm at the museum is not part of the task set of listening to the guide’s discussion of Hieronymous Bosch, but it is clearly a behaviourally relevant stimulus.

\item
visuo- proprioceptive conflict (Balslev et al., 2005), and multi-modal detection of sensory changes (Downar et al., 2000)
brain areas connected to aRTPJ further responded to all changes of visual, auditory, or tactile stimulation in a multi-modal fMRI study (Downar et al., 2000).

\item
direct electrical stimulation of the RTPJ during neurosurgery was associated with altered perception and stimulus awareness (Blanke et al., 2002).

\item
the aRTPJ network is central for sensorimotor control by integrating supramodal stimulus-guided attention and action initia- tion during externally structured tasks.

\item
Bzdok2013

pRTPJ cluster was also functionally associated with deception tasks

qualify RTPJ as a po- tential switch between exteroceptive and interoceptive mind sets implemented by their networks. The reciprocal nature of those mind sets is well illustrated by consistent reports of continuous shifting be- tween externally (i.e., sensory) and internally (i.e., self- and presumably social/memory-) oriented processing in controlled laboratory settings and daily routine (Smallwood et al., 2007).
\end{itemize}



\item
  LTPJ
  \begin{itemize}
\item
the difference between the two task groups could be parsimoniously explained by the required atten- tion to either the external world or self.
world -> policy matrix driven computation
self -> value matrix driven computation

\item
significantly reduced impact of intentions after transient TPJ disruption (Young et al. 2010b)

\item
complex conceptual linguistic functions are proposed to be more strongly left-lateralized -> in line with overall left-lateralization of human language


\item
Episodic and explicit memory retrieval strongly draws on complex semantic processing and contributes to social cognitive processes (see section 4.4.). Syntactic processing, on the other hand, is a core language process that is closely intermingled with semantic processing. It refers to the hierarchical sequencing of words and their meanings (Price, 2010) and is mandatory for sentence processing in both social cognitive and language tasks.

\item
only the left TPJ was associated with language processes, whereas only the right TPJ was functionally associated with attention processes

\item 
Wernicke's area:
involved in accessing and integrating world knowlege.
involved in the comprehension or understanding of written and spoken language Damage caused to Wernicke's area results in receptive, fluent aphasia. This means that the person with aphasia will be able to fluently connect words, but the phrases will lack meaning.
A major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal syntax. Language as a result is largely meaningless. difficulty finding words, putting words in the wrong order, substituting sounds and/or words, difficulty understanding spoken utterances, difficulty recognizing some words by sight, difficulty writting letters



\item a lesion study on disturbed sleep (i.e., a state of mind
independent of sensory stimulation but dependent on
internally generated information) exclusively identified
the dmPFC (Koenigs et al., 2010). Third, another VLSM study exclusively
related the IFG and TPJ, both more strongly connected to the
dmPFC in our study, to inner speech
\end{itemize}






\item HC:
\begin{itemize}
  \item
The HC, in turn, is well known to be involved in memory and spatial navigation in animals and humans (von Bechterew, 1900; Scoville and Milner, 1957; O’Keefe and Dostrovsky, 1971; Maguire et al., 2000).

\item
hippocampal damage [21,38–40] is associated with an impairment in thinking about one’s personal future

\item
They found that amnesic patients with bilateral hippocampal damage were markedly impaired relative to matched control subjects at imagining new fictitious experiences (Figure 1). Moreover, Hassabis et al. [21] identified a possible source for this deficit. Although patients were able to produce considerable detail when asked to imagine fictitious new experiences, their descriptions lacked spatial coherence and were instead fragmented and considerably less rich [21].

\item
 empirical evidence hinting at a two-process function of the hippocampus comes from structural MRI studies of expert navigators (London taxi drivers) who show increased grey matter volume in posterior hippocampus seemingly at the expense of reduced grey matter volume in anterior hippocampus (Maguire et al. 2006b). Moreover, their increased spatial knowledge appears to come at a cost to the acquisition of new visual associative information (Maguire et al. 2006b; Woollett \& Maguire 2009). 

\item
Schachter/Buckner:
The network described here is tied to the medial temporal lobe system, which is traditionally considered almost exclusively in the context of remembering the past. We suspect the adaptive value of
episodic memory is not solely in its ability to afford mental reconstruction of the past but rather in its contribution to building mental models – simulations – of what might happen next or other perspectives on the immediate envir- onment, such as what others are thinking (see Ref. [63]). As

\item
the GMV of the entorhinal cortex (connectionally and functionally closely coupled with the HC) correlated with social network size (Kanai et al., 2012)


\item 
In fact, phase-locked hippocampal?<80><93>cortical loops have been proposed t
formation of mnemonic neuronal representations
**a large body of animal and human literature relates
hippocampal-prefrontal theta to memory and memory to the DMN**


\item 
A special case is the hippocampus whose highly recursive connection matrix is thought to function as a large ‘autoassocia- tor’, allowing the reconstruction of entire episodes from remembered fragments.

\item
hippocampal pyramidal cells during rest and sleep produce strongly coherent ensemble bursts believed to be critical in transferring information to the neocortex.

\item
sequential single- cell recording could reveal such cooperative patterns

\item
buszaki2004 theta oscillations:
Using large-scale recordings, researchers can follow complex patterns for extended time periods and determine whether their modification by experience will influence self-generated patterns in the absence of envi- ronmental inputs. Spike sequences, imposed upon the network by behavioral manipulations, recur spontaneously during subsequent sleep
indicating that neurons organize themselves into preferred cell assemblies, and the seeds of emergence stem from experi- ence-related activity.
 Such internally driven, self-organized assemblies may reflect mechanisms that give rise to cognitive phenomena
 Sharp-wave ripples are believed to be the transfer mechanism of information from the hippocampus to neocortex during off-line (eg, sleep) states.
Neurons, mostly studied in the hippocampus, which fire action potentials only when the animal is in a specific place in a given environment (that place where a cell fires is called the “place field” of that cell).
-> self-play in deepmind Go

\item
statistical structure of hippocampal activity ->
spatial maps of surroundings are encoded

\item
Numerous experiments have demonstrated that hippocampal neurons show place-related firing while the rat explores or traverses its environment so that each assembly of hippocampal principal cells defines a particular position of space 

\item
Diba + Buzsaki 2007
We report that temporal spike sequences from hippocampal place neurons of rats on an elevated track recurred in reverse order at the end of a run, but in forward order in anticipation of the run, coinciding with sharp waves. Vector distances between the place fields were reflected in the temporal structure of these sequences. This bidirectional re-enactment of temporal sequences may contribute to the establishment of higher-order associations in episodic memory.

\item
coding, transfer, and consolidation of
information
This emerging picture of hippocampal dy- namics suggests that neurons at the opposite ends of the distributions may convey differ- ent but complementary types of information. The ever-active minority of place cells may be responsible for generalizing across envi- ronments and affords the brain the capacity to regard no situation as completely un- known because every alley, mountain, river, or room has elements of previously experi- enced similar situations. In many situations,
this minority provides the “best guess” of the hippocampus and offers “good enough” solutions to get by. On the other hand, the majority of less active neurons constitute a large reservoir that can be mobilized (7) to precisely distinguish one situation from an- other and incorporate novel ones as distinct.


\item
damage to even the hippocampus alone is sufficient to cause amnesia +
envisoning themselves in future and even hypothetical scenarios/mentally constructing new experiences

The HC, in turn, is well known to be involved in memory and spatial navigation in animals and humans (von Bechterew, 1900; Scoville and Milner, 1957; O’Keefe and Dostrovsky, 1971; Maguire et al., 2000). 

\item
Hassabias2007:
Recollection of these rich autobiographical or episodic memories has been likened to mentally traveling back in time and re-experiencing one’s past (1). It has long been known that the hippocampus and related medial temporal lobe structures play a critical role in supporting episodic memory

In fact, episodic memory and imagining or constructing events share striking similarities in terms of the psychological processes engaged (19–21). These include imagery (22), sense of presence (1), retrieval of semantic information and multimodal details (23), and narrative structure (22).

visual imagery itself is not believed to be realized in the HC

  \end{itemize}
\end{itemize}




\section{Methods}

\subsection{Linear control network model for brain organization}
Consider the following linear time-invariant (LTI) dynamical system as a (toy) model for high-level brain function
\begin{equation}
  \dot{\x}(t) = \A\x(t) + \B\u(t).
  \label{eq:lti}
\end{equation}
Here, the $n$-by-$n$ matrix $\A$ denotes a model of the brain's wiring (for example a resting state connectome computed from an anatomical atlas), while the $n$-by-$k$ ``input matrix'' $\B$ describes which nodes can be controlled by us, an external \textit{controller}, via medical intervention or a careful choice of stimulus presentation, for example.
At time $t \ge 0$, let  the $n$-vector  $\x(t) := (\x_1(t),\ldots,\x_n(t))$ encodes the state of the network (one value for each node). The aim is to supply values of $\u_1(t),\ldots,\u_k(t)$ for $k \le n$ controls as a function of the time $t$,  to take the system from any prescribed initial state $\x(0) = \x^{\text{init}} \in \mathbb R^n$ to any prescribed final state $\x(\tau) = \x^{\text{fin}} \in \mathbb R^n$ in finite time $\tau < \infty$.
When such a controlling is possible, we say that the system $(\A,\B)$ is \textit{controllable}. A precise sufficient and necessary condition for such controllability is the Kalman condition: $(\A,\B)$ is controllable iff the $n \times nk$ \textit{controllability matrix}
\begin{equation}
  \C := (\B|\A\B|\ldots|\A^{n-1}\B)
\end{equation}
has full rank, i.e
\begin{equation}
  rank(\C) = n.
\end{equation}

\paragraph{How many controls do we need at best ?}
In the thermodynamic limit ($n \rightarrow \infty$), statistical physics \cite{Liu2011} gives the extremely good estimate
\begin{equation}
  n_0(\langle k\rangle, \gamma) \approx \exp\left(-\frac{1}{2}\left(\frac{\gamma-2}{\gamma - 1}\right)\langle k \rangle\right),
\end{equation}
where $\gamma \ge 1$ is the \textit{scale-free} parameter for the node-degree distribution of the network described by $\A$, and $\langle k \rangle$ is the mean degree. Letting $\gamma \rightarrow \infty$, one recovers the Erdos-Renyi value
\begin{equation}
  n_0(\langle k\rangle) = \exp\left(-\frac{1}{2}\langle k\rangle\right),
\end{equation}
which agrees perfectly with its known analytic value. One identifies two radically different regimes:
\begin{itemize}
  \item the manageable regime $\gamma > \gamma_c := 2$, in which $n_0 < 1$, and so we only need fewer controls than total number of nodes, and
\item the unmanageable regime ``$\gamma \le \gamma_c$'', in which  $n_0 = 1$, where each node must be controlled explicitly.
\end{itemize}

\paragraph{Why linear dynamics ?}
As explained in \cite{Liu2011}, the choice of linear dynamics over a more general nonlinear dynamics can be justified as follows:
\begin{itemize}
  \item  Conclusions drawn from linear dynamics can be
extended to nonlinear systems.
\item If the controllability matrix of the linearized system
has full rank at all points, then it is sufficient for most
systems to say that the actual nonlinear system is
controllable (i.e. small signal model).
\end{itemize}

\paragraph{A note on stability.}
For stability in the LTI model \eqref{eq:lti} and hence in the constrained path integral \eqref{eq:hj} below, a sufficient (and necessary ?) condition is that all eigenvalues of the $A$ have negative real-part. One way to impose this is to add self-loops with a small negative weight.
\paragraph{Meta brain.}

\subsection{Optimal control: an LQR feedback controller}
We propose to use a linear quadratic regulator (LQR) for the feedback controller. Thus, consider the time-varying \text{value function} $V: [0, \tau] \times \mathbb R^n \rightarrow \mathbb R$, defined by the following Hamilton-Jacobi cost-to-go
\begin{equation}
  \begin{split}
    &V(t, \z) := \min_{\u} \frac{1}{2}\x_{\text{fin}}^T\Q_{\text{fin}}\x_{\text{fin}} + \int_{0}^\tau\left(\frac{1}{2}\x(t)^T\Q\x(t) + \frac{1}{2}\u(t)^T\R\u(t)\right)dt,\\
    &\text{subject to } \x(t) = \z, \dot{\x}(t) = \A\x(t) + \B\u(t),
  \end{split}
  \label{eq:hj}
\end{equation}
where the matrices $\Q$ and $\R$, precised by design considerations and subject to meta-optimization, are restricted to be positive semi-definite and positive definite, respectively. A classical calculation (reminiscent of the \textit{Pontryagin minimization principle}) reveals that the optimal feedback control in \eqref{eq:hj} is given by
\begin{equation}
  \u(t) = -\K(t)\x(t),
\end{equation}
where
\begin{equation}
  \K(t) := \R^{-1}\B^T\P(t)\text{ (Kalman gain matrix)}
\end{equation}
and the time-varying positive semi-definite matrix $\P(t)$ solves following differential Riccati equation (DRE)
\begin{equation}
\begin{split}
&-\dot{\P}(t) = \A^T\P(t) + \P(t)\A - \P(t)\B\R^{-1}\B^T\P(t) + \Q\\
&\text{subject to }\P(\tau) = \Q_{\text{fin}}.
\end{split}
\end{equation}
%% \subsection{Minimal control energy controller}
\subsubsection{Related works}
The model proposed in \cite{betzel2016} can be cast in the form \eqref{eq:hj}, with the particular choice $\Q = \textbf{I} = \rho^{-1}\R$ and $\Q_{\text{fin}} = \textbf{0}$, but with a rather ad-hoc handle on stability issues and choice driver nodes...

\subsection{Demystifying the free-energy principle}
In this section we will develop from first-principles, the bare-bones minimalistic ideas needed to build a free-energy principle for general decision making. This ideas were first developed by Hinton et al. in the early 90s in the form of the so-called  \textit{Helmholtz machine}. Theories like Friston's free-energy principle will then emerge as particular instanstances of this general framework, with particular design choises. For example the Friston theory assumes the brain uses a (problematic) wake-sleep algorithm to train the underlying Helmholtz machine, etc.
\begin{table}[H]
  \begin{tabular}{p{2cm}|p{11cm}}
         \hline
         \textbf{variable}    & \textbf{short description}  \\ \hline
             $\langle E\rangle_p$ & Expectation (a.k.a average) of the random quantity $E$
         .r.t to the probability density $p$.\\ \hline
         $\mathcal H$ & The usual information-theoretic entropy operator.\\ \hline
         $D_{KL}(p||q)$ & The Kullback-Leibler divergence between the probability densities $p$ and $q$. \\ \hline
             $\zeta$ & Observations. In Friston's free-energy principle this has a decomposition in to two terms: the brain's hidden state $b$ and sensory inputs $s$, i.e $\zeta = (s, b).$ \\ \hline
             $\psi$ & Hidden variables. This should be understood as the unobservable states of the external environment (to which the brain is trying to adapt by learning).\\ \hline
             $p_G(.|\zeta)$ & Generative density for ...\\ \hline
         $p_R(.|\zeta)$ & Recognition density for ... Does some kind of predictive coding (?).\\ \hline
         $F_G(\zeta)$ & Helmholtz free-energy for the model $p_G$ of generating the observation $\zeta$.\\ \hline
         $F^R_G(\zeta)$ & Variational Helmholtz free-energy from $R$ to $G$.  Note that $F^G_G = F_G$.\\ \hline
  \end{tabular}
  \caption{Table of notations.}
\end{table}
\subsubsection{Helmholtz free-energy and the generative model}
Our starting point will be to build an approximation $p_G$ for the true density $p$ of the observations, so that this approximate density corresponds to the partition function of thermodynamic system. So,
\begin{eqnarray}
  \begin{split}
    \text{generative surprise } &= -\log(p_G(\zeta)) = -\log(p_G(\zeta)) \times 1 = -\log(P_G(\zeta))\sum_{\psi}p_G(\psi |\zeta)\\
    &= -\sum_{\psi}p_G(\psi, \zeta)\log(p_G(\zeta))
    =-\sum_{\psi}p_G(\psi |\zeta)\log(p_G(\psi, \zeta)/p_G(\psi|\zeta))\\
    &= \sum_{\psi}p_G(\psi |\zeta)\log(p_G(\psi|\zeta))-\sum_{\psi}p_G(\psi |\zeta)\log  (p_G(\psi, \zeta))\\
    &= -\langle \log  (p_G(., \zeta)) \rangle_{p_G(. |\zeta)} - \mathcal H(p_G(. |\zeta))\\
    &= \langle E_G(., \zeta) \rangle_{p_G(. |\zeta)} - \mathcal H(p_G(. |\zeta)) := F_G(\zeta)
  \end{split}
  \label{eq:helm}
\end{eqnarray}
where $E_G(\psi, \zeta)$ is the energy of an fictive thermodynamic system defined by setting
\begin{equation}
  E_G(\psi, \zeta) := -\log(p_G(\psi, \zeta)).
  \label{eq:gibbs}
\end{equation}
%% In the above, the variable $\psi$ is a hidden variable, and can / should be interpreted as the unobservable state of the external world.
The last quantity $F_G(\zeta) := \langle E_G(., \zeta) \rangle_{p_G(. |\zeta)} - \mathcal H(p_G(. |\zeta))$ in \eqref{eq:helm} can be is nothing other than the Helmholtz free-energy for the physical system correspond to the external world, prescribed by the generative density $p_G(\psi|\zeta)$ for the occupation of \textit{macrostates} $\psi$. Thus generative surprise and generative Helmholtz free-energy are different views on exactly the same object.

The goal of the agent is then to optimize over the generative model $G$ (i.e over the generative density $p_G(.|s)$, so as to minimize their surprise. It turns out that a direct attempt to attack this optimization problem by gradient descent on the free-energy $F_G(s)$ is furtile: the parameter update steps are not ``very clean'', and require rather cumbersome and heavy computations. A workaround is then to introduce a second density $p_R(.|\zeta)$ called a \textit{recognition} density to work in tandem with the generative density $p_G(.|\zeta)$: the former dreams / fantacizes whilst the latter tries to generate sensations which match these dreams! This primal-dual idea is at the heart ot the (variational) free-energy principle that we'll introduce shortly.

\subsubsection{Variational Helmholtz free-energy and the recognition density}
In this subsection we'll develop a very insightful upper bound for the generative surprise (i.e generate Helmholtz free-energy), called the \textit{variational} (Helmholtz) free-energy. As an avant-gout of what is to come shorty, let's just that the well-known \textit{free-energy principle} is simply a workaround whereby the minimization surprise (intractable) is replaced with the  minimization a carefully chosen upper bound of it instead.

Now, invoking \eqref{eq:gibbs} and applying Bayes rule, we get the Gibbs
distribution
\begin{equation}
  p_G(\psi|\zeta) = \frac{p_G(\psi|\zeta)}{p_G(\zeta)} = \frac{\exp(-E_G(\psi, \zeta))}{Z_G(\zeta)} = \frac{\exp(-E_G(\psi, \zeta))}{Z_G(\zeta)},
\end{equation}
where $Z_G(\zeta) := \log(p_G(\zeta)) = \sum_{\psi'}\exp(-E_G(\psi',\zeta))$, the normalizing partition function for the model \ref{eq:gibbs}.
Whence $\forall \psi$, $Z_G(\zeta) = p_G(\zeta) = \exp(-E_G(\psi, \zeta)) / p_G(\psi|\zeta)$, and so we have the invariance relation
\begin{equation}
  -\log(Z_G(\zeta)) = -\log(p_G(\zeta)) = F_G(\zeta) = E_G(\psi, \zeta) + \log(p_G(\psi|\zeta)).
  \end{equation}
Now, in the equation above, the LHS only depends on the generative model $G$ and the data point $s$: it doesn't depend on the hidden variable $\psi$, etc. So, taking expectations w.r.t an arbitrary density\footnote{The conditioning in $P_R(.|\zeta)$ is because this density is selected from a world in which the sensory inputs and internal brain state vector $\zeta$ is assumed already observed.} $p_R(.|\zeta)$ (the subscrit $R$ stands for ``recognition'', and the terminology will become clear in a moment) yields
\begin{equation}
  \begin{split}
    F_G(\zeta) &= -\log(Z_G(\zeta)) = \langle E_G(., \zeta)\rangle_{P_R(.|\zeta)} + \sum_{\psi}p_R(\psi|\zeta)\log(p_G(\psi|\zeta))\\
    &= \langle E_G(., \zeta)\rangle_{P_R(.|\zeta)} - \mathcal H(p_R(.|\zeta)) - \sum_{\psi}p_R(\psi|\zeta)\log(p_R(\psi|\zeta)/p_G(\psi|\zeta))\\
    &= F^R_G(\zeta) - D_{KL}(P_R(.|\zeta) || P_G(.|\zeta)),
  \end{split}
  \label{eq:fe}
\end{equation}
where $F^R_G(\zeta)$ is the \textit{variational} Helmholtz free-energy from $R$ to $G$ defined by
\begin{equation}
  F^R_G(\zeta) := \langle E_G(., \zeta)\rangle_{P_R(.|\zeta)} - \mathcal H(p_R(.|\zeta))
\end{equation}
and $D_{KL}(P_R(.|\zeta) || P_G(.|\zeta))$ is the Kullback-Leibler divergence between the $p_R(.|\zeta)$ and the generative density $p_G(.|\zeta)$. Note that $F^G_G = F_G$.

\subsubsection{A general free-energy principle}
We can resume the situation as follows:
\begin{mdframed}
\begin{equation}
  \begin{split}
    \text{generative surprise } &:= -\log(p_G(\zeta)) = \underbrace{F_G(\zeta)}_{\text{generative free-energy}} \\
    &=\underbrace{F^R_G(\zeta)}_{\text{variational free-energy}} - \underbrace{D_{KL}(P_R(.|\zeta) || P_G(.|\zeta))}_{\text{complexity}} \\
    &\le F^R_G(\zeta),
    \text{ with equalitity if }p_R(.|\zeta) = p_G(.|\zeta),
    \end{split}
\end{equation}
\end{mdframed}
where we have used the fact that KL divergence is always nonnegative. In fact, we have the following theorem
\begin{theorem}
  It holds that
  $$
  \text{Minimal generative surprise = minimal (Helmholtz) variational free-energy},$$
  i.e
  \begin{equation}
    \min_{G}F_G(\zeta) = \min_{G,R}F^R_G(\zeta)
    \end{equation}
\end{theorem}

\subsubsection{Helmholtz machines}
...
\subsection{The wake-sleep algorithm}
...
\subsection{Friston's active-inference: an application of the Dayan's wake-sleep algorithm for training a Helmholtz machine model for the brain}
...

%% \subsection{A thermodynamic model for bounded rationality, aka robust optimality}
%% \begin{itemize}
%%   \item Recall that an agent is said to have \textit{bounded rationality} if they must take into account the cost of finding solutions to problems, and not just the utility of the final state.
%%   \item For example, consider an agent that must operate under a limited lifetime and/or computation cost.
%%   \item This is in contrast to agents with \textit{unbounded rationality} considered in classical game theory.
%%     \end{itemize}
%% The material presented is a revisit of \cite{braun2011path}. See also \cite{ortega2013thermodynamics}
%% \paragraph{Utility functions and conjugate pairs.}
%%   Let $(\Omega, \mathcal F, P)$ be a probablity space. A function $U: \mathcal F \rightarrow \mathbb R$ is said to be a \textit{utility function} for this space if the conditional utility $U(A|B) := U(A \cap B) - U(B)$ has the following propertites:
%%   \begin{itemize}
%%   \item additivity: $U(A_1 \cap A_2 | B) = U(A_1|B) + U(A_2|B)$, for all events $A_1, A_2, B \in \mathcal F$.    
%%   \item statistic: there exists a function $f_{U} :\mathbb R_+ \rightarrow \mathbb R$ such that $U(A|B) = f(P(A|B))$, for all events
%%     $A,B \in \mathcal F$.
%%   \item monotonicity: $f_{U}$ is strictly increasing.
%%     \end{itemize}

%% \begin{theorem}
%%   The only functions $f: \mathbb R_+ \rightarrow \mathbb R$ which is such that $U(A|B) \equiv f(P(A|B))$ any probability space $(\Omega, \mathcal F, P)$ and utility function $U$ thereupon are of the form
%%   \begin{equation}
%%     f = \alpha \log(.),
%%     \label{eq:boltzmann}
%%   \end{equation}
%%   where $\alpha > 0$.
%% \end{theorem}

%% \textbf{XXX: equation \eqref{eq:boltzmann} above looks like Boltzmann's formula (on his gravestone...)!}

%% Such $U$ and $P$ are said to form a \textit{conjugate pair} at temperature $\alpha$.


%% \paragraph{Example.}
%% Given a utility function $U$ on a probability space $(\Omega, \mathcal F, *)$, the \textit{Gibbs measure} at temperature $\alpha > 0$ and energy levels $(-U(\omega))_{\omega \in \Omega}$ is defined to be the probability measure (on thesame measurable space)
%%   \begin{equation}
%%     P(\omega) = \frac{1}{Z_{U}(\alpha)}\exp\left(\frac{1}{\alpha}U(\omega)\right), \; \forall \omega \in \Omega,
%%   \end{equation}
%%   where

%%   \begin{equation}
%%     Z_{U}(\alpha) := \sum_{\omega \in \Omega}\exp\left(\frac{1}{\alpha}U(\omega)\right)
%%   \end{equation}
%%   is a normalization constant called the \textit{partition function} of $U$.
%%   It's not hard to see that $U$ and the $P$ above form a conjugate pair.

%%   \paragraph{Free-utility functional.}
%%     Let $(U, P)$ be a conjugate pair at temperature $\alpha > 0$  on a measurable space $(\Omega, \mathcal F)$. Given another probability measure $P'$ on the same space, define it's \textit{free utility} as
%%     \begin{equation}
%%       J(P'|U, P) = \langle U \rangle_{P'} + \alpha \mathcal H(P'),
%%     \label{eq:free_u}
%%     \end{equation}
%%     where
%%     \begin{equation}
%%       \mathcal H(P') := \langle \log(P') \rangle_{P'} := -\sum_{\omega \in \Omega}P'(\omega)\log(P'(\omega))
%%     \end{equation}
%%     is the \textit{entropy} of $P'$ (measured in the Naperian base $e \approx 2.73$). It's not difficult to establish the upper bound
%%   \begin{equation}
%%     J(P'|U) \le J(P|U) = \sum_{\omega \in \Omega}U(\omega) =: U(\Omega).
%%   \end{equation}
%%   In particular, if $P$ is the Gibbs measure at temperature $\alpha$ corresponding to $U$, then the upper bound above reduces to the \textit{log-partition function}
%%   \begin{equation}
%%     J(P'|U) \le U(\Omega) = -\alpha \log(Z_{U}(\alpha)).
%%     \end{equation}

%%   \paragraph{The free-energy / utility principle (of Friston ?).}
%%   We are now in shape to introduce the notion of free-energy for model transitions, and a variational principle for optimizing it. Consider thus an initial system described by a conjugate pair $(U_{\text{ini}}, P_{\text{ini}})$ at temperature $\alpha > 0$. We want to transform this to a new model by adding constraints represented by the utility function $\Delta U$.  The resulting system has final utility $U_{\text{fin}} = U_{\text{ini}} + \Delta U$. The difference in free-utility is then
%%   \begin{equation}
%%     \Delta J_{(U_{\text{ini}}, P_{\text{ini}}) \rightarrow P_{\text{fin}}} := J_{\text{fin}} - J_{\text{ini}} = \underbrace{\langle \Delta U\rangle_{P_{\text{fin}}}}_{\textbf{accuracy}} -  \underbrace{\alpha D_{\text{KL}}(P_{\text{ini}}\|P_{\text{fin}})}_{\textbf{complexity}},
%%     \label{eq:free}
%%   \end{equation}
%%   where
%%   \begin{equation}
%%     D_{\text{KL}}(P_{\text{fin}}\|P_{\text{ini}}) := \langle \log(\P_{\text{fin}}/\P_{\text{ini}})\rangle_{\P_{\text{fin}}} := \sum_{\omega \in \Omega}\P_{\text{fin}}(\omega)\log(\P_{\text{fin}}(\omega)/\P_{\text{ini}}(\omega))
%%   \end{equation}
%%   is the Kullback-Leibler divergence, and represents the information cost (measured in energy units) of changing the initial system.
%% In the above formula, we've extensively used the fact that $(U_{\text{ini}}, P_{\text{ini}})$ is a congugate pair and so $U_{\text{ini}}(\omega) \equiv \alpha \log(P_{\text{ini}}(\omega))$ by virtue of \eqref{eq:boltzmann}.
%%   The two terms in \eqref{eq:free} (accuracy or expected gain in utility, and the complexity of the transition) can be viewed as dertiminants of bounded rational decision-making. They formalize
%% a trade-off between an expected utility $\Delta U$ (first term) and
%% the information cost of transforming Pi
%% into $P_{\text{fin}}$ (second
%% term). In this interpretation $P_{\text{ini}}$ represents an initial choice
%% probability or policy, which includes the special case of the
%% uniform distribution where the decision-maker has initially no
%% preferences between the different choices. The probability measure $P_{\text{fin}}$ is the final choice probability that we are looking for since it
%% considers the utility constraint U∗
%% that we want to optimize. We can then formulate a variational principle for bounded rationality in the probabilities $P_{\text{fin}}(\omega)$
%% \begin{equation}
%% P^*_{\text{fin}} := \underset{P_{\text{fin}}}{\text{argmax }} \Delta J_{(U_{\text{ini}}, P_{\text{ini}}) \rightarrow P_{\text{fin}}}
%%   \end{equation}

%% By differentiating the RHS of \eqref{eq:free} w.r.t $P_{\text{fin}}$ and setting to zero, we obtain the closed-form solution

%% \begin{equation}
%%   P^*_{\text{fin}}(\omega) \propto P_{\text{ini}}(\omega)\exp\left(\frac{1}{\alpha}\Delta U(\omega)\right).
%% \end{equation}

%% Two limit cases are worth considering.
%% \begin{itemize}
%% \item \textbf{Low-temperature regime $\alpha \approx 0$:} Here $\Delta J_{(U_{\text{ini}}, P_{\text{ini}}) \rightarrow P_{\text{fin}}} \approx \langle \Delta U\rangle_{P'_{\text{fin}}}$, and so it's optimal to take
%%   $$P^*_{\text{fin}}(\omega) \equiv \text{dirac}(\omega - \omega^*) = \begin{cases}1, &\mbox{if }\omega = \omega^*,\\0, &\mbox{ otherwise,}\end{cases}$$
%%   where $\omega^* := \argmax_{\omega \in \Omega}U(\omega)$. This corresponds to unbounded rational decision-making, in which the cost of transition / problem-solving is completely disregarded.
%%   \item \textbf{High-temperature regime $\alpha \rightarrow +\infty$:} In this limiting case, it's optimal to take $P^*_{\text{fin}}(\omega) \equiv P_{\text{ini}}(\omega)$, i.e the change is so costly that it's optimal to maintain the current choice probabilities.
%% \end{itemize}

%% To conclude this section, let's note that \cite{braun2011path} show how their free-energy framework (on paths) links with the well-known Hamilton-Jacobi-Bellman optimal control framework. For example, one can re-derive the Linear Quadratic Gaussian (LQG) controller, which is a generalization of the LQR in \eqref{eq:hj}...


\section{Relation to Other Cognitive Models (Danilo)}
\paragraph{Predictive Coding and Bayesian Brain Hypothesis}
abc
The Predictive Coding Framework.
construction of detached probabilistic scenes has been argued to influence ongoing decision-making by estimating outcomes of behavioral choices.

\begin{itemize}
  \item It is one of the most frequently cited hypotheses of default mode function
  \item Within this model the brain is conceptualized as a Bayesian machine
  \item Predictive coding is a framework that, in a hierarchical setting,
  is equivalent to empirical Bayesian inference
  \item External sensory input is feed-forward/bottom-up processed in the brain
  \item Their processing is compared against expected input
  \item The prediction error, i.e. the difference between sensory input
  and internal prediction, is computed at each level and passed to
  higher levels via forward connections
  \item in case of a mismatch, back-projections top-down modulate
  input processing
  \item ‘contextual integration’ for top-down modulation of sensorimotor
  processing by context-specific a-priori information.
  \item Closely related to Friston's free-energy principle: brain as inference engine
  biological systems, including brains, must minimize the long-term average of surprise;
  formulate perception as a constructive process based on internal or generative models
  \item A generative model of the world
\end{itemize}

Friston2014:

This perspective shifts away from the brain as a passive filter of sensations (or an elaborate stimulus– response link) towards a view of the brain as a statistical organ that generates hypotheses or fantasies that are tested against sensory evidence. In short, the brain is now considered a phantastic organ (from Greek phantastikos, the ability to create mental images). For many people, this perspective can be traced back to Hermann von Helmholtz and the notion of unconscious inference: that is, a pre-rational mechanism by which visual impressions are formed (eg, the seemingly automatic but erroneous belief that the sun rises and sets in the sky, as opposed to the truth that the Earth rotates around it).

Predictive coding is not a normative or descriptive scheme, it is a process theory with a biologically plausible basis—there is now much circumstantial anatomical and physiological evidence for predictive coding in the brain.12–16 In this scheme, neuronal representations in higher levels of cortical hierarchies generate predictions of representations in lower levels. These top-down predictions are compared with representations at the lower level to form a prediction
error (associated with the activity of superficial pyramidal cells). This mismatch signal is passed back up the hierarchy, to update higher representations (associated with the activity of deep pyramidal cells).

A description of biological processes as minimising (variational) free energy—a statistical measure of the surprise or improbability of sensory data, under a model of how those data were generated.

predictive coding represents a biologically plausible scheme that enables the brain to update beliefs about the world with sensory samples

 individuals spend most of their time predicting the internal (proprioceptive) and external (exteroceptive) consequences of behaviour (both their own and that of others). To fully appreciate the bilateral nature of these predictions, inference can be considered in an embodied context. In this setting, perception can be understood as resolving exteroceptive prediction errors by selecting the predictions that best explain sensations. Conversely, behaviour suppresses pro- prioceptive prediction error by changing proprioceptive sensations. This suppression relies on classic reflexes, in which equilibrium points are set by descending proprioceptive predictions (figure 1).15 This process is called active inference

providing a rich dynamical repertoire that enables the brain to respond quickly to changing inputs

the formal constraints implicit in predictive coding mandate modulatory gain control for ascending prediction errors




\paragraph{Semantic Hypothesis}
abc

\paragraph{Sentinel Hypothesis}
many investigators speculate that this central neural network reflects the brain’s relentless tracking and prediction of environmental events to adaptively optimize the organism's future action (Schacter et al., 2007).

Cognitive neuroimaging studies linked the DMN to the contemplation of others’ (Mar, 2011) and one’s thoughts (Lombardo et al., 2009) mental states, 

DMN does social cognition -> but it exists in rats and monkeys with much more poorly developped social capacities

How can a same neurobiological circuit be equally important for baseline house-keeping functions and specific task performance?

Our computational account can explain why the DMN is implicated in both a goal-directed task and an idlying rest cognitive set? -> task is policy/value updates to optmize short-term action / rest updates for mid- and long-term action


\section{Relation to Other Statistical Models (Elvis)}
\paragraph{Control Theory.}
abc

\paragraph{Reinforcement Learning.}
abc

\paragraph{Free Energy Principle.}
The free-energy principle in it's present form (including notions like ``generative density'', ``recognition density'', etc.) can be traceback to works of Dayan \& Hinton \cite{dayan1995helmholtz} in which the introduced the so-called Helmholtz machine...

\begin{itemize}
  \item Ortega et al. 2013 \cite{ortega2013thermodynamics} ``Thermodynamics as a theory of decision-making with information-processing costs''
\item Friston's critic of RL \cite{fristonAIorRL} (he proposes "active inference''): "This equation (equation 18) comes from the theory of dynamic programming,
pioneered in the 1950s by Richard Bellman and colleagues [2]. To
optimise control a~pð Þ x~ under this formulation, we have to: (i)
assume the hidden states are available to the agent and (ii) solve
Equation 18 for the value-function. Solving for the value-function
is a non-trivial problem and usually involves backwards induction
or some approximation scheme like reinforcement-learning [4–6].
The free-energy formulation circumvents these problems by
prescribing the policy in terms of free-energy, which encodes
optimal control (Equation 6)"
  \end{itemize}

\section{Conclusion}
What single brain function could be most important for existence and survival of the species?
From the perspective of the human condition, it remains unclear what the nature and purpose of a domain-overarching computational mechanism implemented in the high association cortex could be to warriant the high energetic costs.

; formalize and predict; offer statistical control on the brain's default function/operations




\paragraph{Acknowledgment}
% {\small The research leading to these results has received funding from the
% European Union Seventh Framework Programme (FP7/2007-2013)
% under grant agreement no. 604102 (Human Brain Project).
% Further support was received from
% the German National Academic Foundation (D.B.).
% }


\small
\bibliographystyle{splncs03}
\bibliography{nips_refs}

\end{document}
